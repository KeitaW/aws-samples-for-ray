{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03611fc5-1066-4449-923d-6402459a64ab",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is our second notebook which will explore the model training stage of the ML workflow.\n",
    "\n",
    "Here, we will put on the hat of the `Data Scientist` and will perform the task of modeling which includes training a model, performing hyperparameter tuning, evaluating the model and registering high performing candidate models in a model registry. This task is highly iterative in nature and hence we also need to track our experimentation until we reach desired results.\n",
    "\n",
    "We will learn how to bring scale to model development tasks using managed SageMaker training and experiment tracking capabilities combined with curated feature data pulled from SageMaker Feature Store.  You'll also perform tuning at scale using SageMaker's automatic hyperparameter tuning capabilities. Then, finally register the best performing model in SageMaker Model Registry. \n",
    "\n",
    "![Notebook2](images/Notebook2.png)\n",
    "\n",
    "\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "**Important:** for this example, we will use XGBoost-Ray. XGBoost-Ray integrates well with the Ray Tune hyperparameter optimization library and implements advanced fault tolerance handling mechanisms. We will use ray.data to load training, validation and testind data  (in parquet format) from the offline data store of the Feature Store. Then we will run a hyperparamter optimization job to find the best HPs. Finally we will register the best performing model to the Model registry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b1c64f-277a-47ea-adeb-fc3491f4d83c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c22424-be2a-472e-ac30-4dab9a73e716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fs-train--2023-07-04-13-37-02'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c71dd6-df12-4fb2-95e8-4c5714dfe79e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.169.0)\n",
      "Requirement already satisfied: ray==2.5.0 in /opt/conda/lib/python3.10/site-packages (2.5.0)\n",
      "Requirement already satisfied: modin[ray]==0.22.1 in /opt/conda/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: pydantic==1.10.10 in /opt/conda/lib/python3.10/site-packages (1.10.10)\n",
      "Requirement already satisfied: xgboost_ray in /opt/conda/lib/python3.10/site-packages (0.1.16)\n",
      "Requirement already satisfied: tensorboardx in /opt/conda/lib/python3.10/site-packages (2.6)\n",
      "Collecting tensorboardx\n",
      "  Using cached tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (23.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (8.1.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (3.6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (3.2.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (21.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (6.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.3.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (2.31.0)\n",
      "Requirement already satisfied: grpcio<=1.51.3,>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.51.3)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.24.3)\n",
      "Requirement already satisfied: pandas==1.5.3 in /opt/conda/lib/python3.10/site-packages (from modin[ray]==0.22.1) (1.5.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from modin[ray]==0.22.1) (2022.7.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from modin[ray]==0.22.1) (5.9.0)\n",
      "Collecting ray[default]>=1.13.0 (from modin[ray]==0.22.1)\n",
      "  Using cached ray-2.5.1-cp310-cp310-manylinux2014_x86_64.whl (56.2 MB)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from modin[ray]==0.22.1) (12.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.10) (4.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->modin[ray]==0.22.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->modin[ray]==0.22.1) (2022.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.153)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: wrapt>=1.12.1 in /opt/conda/lib/python3.10/site-packages (from xgboost_ray) (1.14.1)\n",
      "Requirement already satisfied: xgboost>=0.90 in /opt/conda/lib/python3.10/site-packages (from xgboost_ray) (1.7.6)\n",
      "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.153 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.153)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.5.0) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of ray[default] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (3.8.4)\n",
      "Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (0.7.0)\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (0.5.5)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (0.3.14)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (1.1)\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (0.11.2)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (0.14.1)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (5.2.1)\n",
      "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray==2.5.0) (20.21.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost>=0.90->xgboost_ray) (1.9.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.5.0) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.5.0) (67.8.0)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.5.0) (2023.5.7)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray==2.5.0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray==2.5.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray==2.5.0) (1.9.2)\n",
      "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray==2.5.0) (11.525.131)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray==2.5.0) (1.20.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv<20.21.1,>=20.0.24->ray==2.5.0) (0.3.6)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray==2.5.0) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray==2.5.0) (2.11.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray==2.5.0) (0.2.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (1.59.1)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (2.21.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==2.5.0) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker ray==2.5.0 modin[ray]==0.22.1 pydantic==1.10.10 xgboost_ray tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52456197-19fc-4a0f-a44e-4c48d167c684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "import sys\n",
    "import sagemaker\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "# SageMaker Experiments\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.utils import unique_name_from_base\n",
    "\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d399b5-90b3-4a20-b3af-decba42e575e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bcb783-f30b-4149-8843-51917d7b10cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful SageMaker variables\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "enable_local_mode_training = False\n",
    "model_name = 'xgboost-model'\n",
    "\n",
    "experiment_name = unique_name_from_base('synthetic-housing-XGB-regression')\n",
    "\n",
    "model_path = f's3://{bucket}/{s3_prefix}/output/model/xgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca98fd9-6cf8-4fd7-9d15-1ac33f912ed7",
   "metadata": {},
   "source": [
    "**Get the `ResolvedOutputS3Uri` of the Feature Group**\n",
    "\n",
    "We can obtain the location where each Feature Group is storing data in parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e80bac9-fbb7-4bfa-8b02-632c73c1d6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-sm-ray-workshop/data/feature-store/train/523914011708/sagemaker/us-east-1/offline-store/fs-train--2023-07-04-13-37-02-1688478127/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_train_group = FeatureGroup(\n",
    "        name=train_feature_group_name, \n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "\n",
    "fs_train_data_loc = fs_train_group.describe().get(\"OfflineStoreConfig\").get(\"S3StorageConfig\").get(\"ResolvedOutputS3Uri\")\n",
    "fs_train_data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8347e1a8-4555-47b8-88d2-3800d44cc1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-sm-ray-workshop/data/feature-store/validation/523914011708/sagemaker/us-east-1/offline-store/fs-validation--2023-07-04-13-37-02-1688478127/data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_val_group = FeatureGroup(\n",
    "        name=validation_feature_group_name, \n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "\n",
    "fs_val_data_loc = fs_val_group.describe().get(\"OfflineStoreConfig\").get(\"S3StorageConfig\").get(\"ResolvedOutputS3Uri\")\n",
    "fs_val_data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1ec1fb-704a-40d2-a6bb-c26bff7e3922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-sm-ray-workshop/data/feature-store/test/523914011708/sagemaker/us-east-1/offline-store/fs-test--2023-07-04-13-37-02-1688478127/data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_test_group = FeatureGroup(\n",
    "        name=test_feature_group_name, \n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "\n",
    "fs_test_data_loc = fs_test_group.describe().get(\"OfflineStoreConfig\").get(\"S3StorageConfig\").get(\"ResolvedOutputS3Uri\")\n",
    "fs_test_data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90e91c-05ee-4a49-bf9c-84158fa026e2",
   "metadata": {},
   "source": [
    "## SageMaker Training\n",
    "\n",
    "Now that we've prepared our training and test data, we can move on to use SageMaker's hosted training functionality - [SageMaker Training](https://docs.aws.amazon.com/sagemaker/latest/dg/train-model.html). Hosted training is preferred for doing actual training, especially large-scale, distributed training. Unlike training a model on a local computer or server, SageMaker hosted training will spin up a separate cluster of machines managed by SageMaker to train your model. Before starting hosted training, the data must be in S3, or an EFS or FSx for Lustre file system. We uploaded to S3 in the previous notebook, so we're good to go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee80286-2472-40e6-836d-cd69be678897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline_scripts/train/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline_scripts/train/script.py\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker','ray', 'xgboost_ray', 'pyarrow >= 6.0.1'])\n",
    "import os\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "# Experiments\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "\n",
    "import ray\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data import Dataset\n",
    "from ray.air.result import Result\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from sagemaker_ray_helper import RayHelper \n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "def read_parameters():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--max_depth', type=int)\n",
    "    parser.add_argument('--eta', type=float)\n",
    "    parser.add_argument('--min_child_weight', type=int)\n",
    "    parser.add_argument('--subsample', type=float)\n",
    "    parser.add_argument('--verbosity', type=int)\n",
    "    parser.add_argument('--num_round', type=int)\n",
    "    parser.add_argument('--tree_method', type=str, default=\"auto\")\n",
    "    parser.add_argument('--predictor', type=str, default=\"auto\")\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output_data_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR'))\n",
    "    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--sm_hosts', type=str, default=os.environ.get('SM_HOSTS'))\n",
    "    parser.add_argument('--sm_current_host', type=str, default=os.environ.get('SM_CURRENT_HOST'))\n",
    "    \n",
    "    parser.add_argument('--num_ray_workers', type=int,default=3)\n",
    "    parser.add_argument('--use_gpu', type=bool, default=False)\n",
    "    # parse region\n",
    "    parser.add_argument('--region', type=str, default='us-east-1')\n",
    "    \n",
    "    parser.add_argument('--target_col', type=str, default='price')\n",
    "    \n",
    "    try:\n",
    "        from sagemaker_training import environment\n",
    "        env = environment.Environment()\n",
    "        parser.add_argument('--n_jobs', type=int, default=env.num_cpus)\n",
    "    except:\n",
    "        parser.add_argument('--n_jobs', type=int, default=4)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def load_dataset(fs_data_loc, target_col=\"price\"):\n",
    "    \"\"\"\n",
    "    Loads the data as a ray dataset from the offline featurestore S3 location\n",
    "    Args:\n",
    "        feature_group_name (str): name of the feature group\n",
    "        target_col (str): the target columns (will be used only for the test set).\n",
    "    Returns:\n",
    "        ds (ray.data.dataset): Ray dataset the contains the requested dat from the feature store\n",
    "    \"\"\"\n",
    "    # Drop columns added by the feature store\n",
    "    cols_to_drop = [\"record_id\", \"event_time\",\"write_time\", \n",
    "                    \"api_invocation_time\", \"is_deleted\", \n",
    "                    'year', \"month\", \"day\", \"hour\"]\n",
    "                    \n",
    "    \n",
    "    # A simple check is this is test data\n",
    "    # If True add the target column to the columns list to be dropped\n",
    "    if '/test/' in fs_data_loc:\n",
    "        cols_to_drop.append(target_col)\n",
    "\n",
    "    ds = ray.data.read_parquet(fs_data_loc)\n",
    "    ds = ds.drop_columns(cols_to_drop)\n",
    "    print(f\"{fs_data_loc} count is {ds.count()}\")\n",
    "\n",
    "    return ds\n",
    "\n",
    "def train_xgboost(ds_train, ds_val, params, num_workers, use_gpu = False, target_col = \"price\") -> Result:\n",
    "    \"\"\"\n",
    "    Creates a XGBoost trainer, train it, and return the result.        \n",
    "    Args:\n",
    "        ds_train (ray.data.dataset): Training dataset\n",
    "        ds_val (ray.data.dataset): Validation dataset\n",
    "        params (dict): Hyperparameters\n",
    "        num_workers (int): number of workers to distribute the training across\n",
    "        use_gpu (bool): Should the taining job use GPUs\n",
    "        target_col (str): target column\n",
    "    Returns:\n",
    "        result (ray.air.result.Result): Result of the training job\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"tree_method\": \"approx\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": [\"mae\", \"rmse\"],\n",
    "    }\n",
    "    \"\"\"\n",
    "    trainer = XGBoostTrainer(\n",
    "        scaling_config=ScalingConfig(num_workers=num_workers, use_gpu=use_gpu),\n",
    "        label_column=\"PRICE\",\n",
    "        params=params,\n",
    "        datasets={\"train\": ds_train, \"valid\": ds_val},\n",
    "        num_boost_round=100,\n",
    "    )\n",
    "    result = trainer.fit()\n",
    "    print(\"<==== Start Training Metrics ====>\")\n",
    "    print(result.metrics)\n",
    "    print(\"<==== END Training Metrics ====>\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Get SageMaker host information from runtime environment variables\n",
    "    sm_hosts = json.loads(args.sm_hosts)\n",
    "    sm_current_host = args.sm_current_host\n",
    "    \n",
    "    hyperparams = {\n",
    "        'max_depth': args.max_depth,\n",
    "        'min_child_weight': args.min_child_weight,\n",
    "        'eta': args.eta,\n",
    "        'subsample': args.subsample,\n",
    "        \"tree_method\": \"approx\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": [\"mae\", \"rmse\"],\n",
    "        \"num_round\": 100\n",
    "    }\n",
    "\n",
    "    ds_train = load_dataset(args.train, args.target_col)\n",
    "    ds_validation = load_dataset(args.validation, args.target_col)\n",
    "    \n",
    "    result = train_xgboost(ds_train, ds_validation, hyperparams, args.num_ray_workers, args.use_gpu, args.target_col)\n",
    "    metrics = result.metrics\n",
    "    checkpoint = result.checkpoint.to_directory(path=os.path.join(args.model_dir, f'model-{metrics[\"trial_id\"]}.xgb'))\n",
    "    trainMAE = metrics['train-mae']\n",
    "    trainRMSE = metrics['train-rmse']\n",
    "    valMAE = metrics['valid-mae']\n",
    "    valRMSE = metrics['valid-rmse']\n",
    "    print('[1] #011train-mae:{}'.format(trainMAE))\n",
    "    print('[2] #011train-rmse:{}'.format(trainRMSE))\n",
    "    print('[3] #011validation-mae:{}'.format(valMAE))\n",
    "    print('[4] #011validation-rmse:{}'.format(valRMSE))\n",
    "    \n",
    "    local_testing = False\n",
    "    try:\n",
    "        load_run(sagemaker_session=sess)\n",
    "    except:\n",
    "        local_testing = True\n",
    "    if not local_testing: # Track experiment if using SageMaker Training\n",
    "        with load_run(sagemaker_session=sess) as run:\n",
    "            run.log_metric('train-mae', trainMAE)\n",
    "            run.log_metric('train-rmse', trainRMSE)\n",
    "            run.log_metric('validation-mae', valMAE)\n",
    "            run.log_metric('validation-rmse', valRMSE)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    ray_helper = RayHelper()\n",
    "    \n",
    "    ray_helper.start_ray()\n",
    "    args = read_parameters()\n",
    "    sess = sagemaker.Session(boto3.Session(region_name=args.region))\n",
    "\n",
    "    start = time.time()\n",
    "    main()\n",
    "    taken = time.time() - start\n",
    "    print(f\"TOTAL TIME TAKEN: {taken:.2f} seconds\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3109f55f-686b-46a9-b74f-bbba2eb66be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp ./common/sagemaker_ray_helper.py ./pipeline_scripts/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a4812b-e374-41e6-a8fd-77eeb047d623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "}\n",
    "\n",
    "train_instance_type = 'ml.c5.2xlarge'\n",
    "\n",
    "estimator_parameters = {\n",
    "    'source_dir': './pipeline_scripts/train/',\n",
    "    'entry_point': 'script.py',\n",
    "    'framework_version': '1.7-1',\n",
    "    'instance_type': train_instance_type,\n",
    "    'instance_count': 2,\n",
    "    'hyperparameters': hyperparams,\n",
    "    'role': role_arn,\n",
    "    'base_job_name': 'XGBoost-model',\n",
    "    'output_path': model_path,\n",
    "    'image_scope': 'training'\n",
    "}\n",
    "\n",
    "inputs = {'train': TrainingInput(fs_train_data_loc), 'validation': TrainingInput(fs_val_data_loc)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "412d4011-c870-4258-9f01-5eb7e257169f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21340/2912256574.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Review the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/synthetic-housing-XGB-regression-1688503056-2258\">Training Job</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.2xlarge.\n",
      "INFO:sagemaker:Creating training-job with name: XGBoost-model-2023-07-04-20-37-38-389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-07-04 20:37:38 Starting - Starting the training job...\n",
      "2023-07-04 20:37:53 Starting - Preparing the instances for training......\n",
      "2023-07-04 20:38:52 Downloading - Downloading input data...\n",
      "2023-07-04 20:39:37 Training - Training image download completed. Training in progress...\u001b[34m[2023-07-04 20:39:48.416 ip-10-0-81-246.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-07-04 20:39:48.435 ip-10-0-81-246.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Module script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:48:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: script\n",
      "  Building wheel for script (setup.py): started\n",
      "  Building wheel for script (setup.py): finished with status 'done'\n",
      "  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=12785 sha256=776fdbc2518c83987a3569fc1424aec83404a1278479fa5eaf1f5fcb1438f079\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-wshy72m1/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built script\u001b[0m\n",
      "\u001b[34mInstalling collected packages: script\u001b[0m\n",
      "\u001b[34mSuccessfully installed script-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:39:50:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"objective\": \"reg:linear\",\n",
      "        \"subsample\": \"0.7\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"XGBoost-model-2023-07-04-20-37-38-389\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":\"0.2\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"XGBoost-model-2023-07-04-20-37-38-389\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--objective\",\"reg:linear\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=reg:linear\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m script --eta 0.2 --max_depth 5 --min_child_weight 6 --objective reg:linear --subsample 0.7\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.169.0.tar.gz (851 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 851.8/851.8 kB 55.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m[2023-07-04 20:39:48.621 ip-10-0-106-43.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2023-07-04 20:39:48.641 ip-10-0-106-43.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:48:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:48:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:49:INFO] Module script does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:49:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:49:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:49:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: script\n",
      "  Building wheel for script (setup.py): started\n",
      "  Building wheel for script (setup.py): finished with status 'done'\n",
      "  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=12785 sha256=776fdbc2518c83987a3569fc1424aec83404a1278479fa5eaf1f5fcb1438f079\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-5h3fjxfw/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built script\u001b[0m\n",
      "\u001b[35mInstalling collected packages: script\u001b[0m\n",
      "\u001b[35mSuccessfully installed script-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:39:50:INFO] Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"max_depth\": \"5\",\n",
      "        \"min_child_weight\": \"6\",\n",
      "        \"objective\": \"reg:linear\",\n",
      "        \"subsample\": \"0.7\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"XGBoost-model-2023-07-04-20-37-38-389\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"eta\":\"0.2\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":\"0.2\",\"max_depth\":\"5\",\"min_child_weight\":\"6\",\"objective\":\"reg:linear\",\"subsample\":\"0.7\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"XGBoost-model-2023-07-04-20-37-38-389\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-523914011708/XGBoost-model-2023-07-04-20-37-38-389/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--objective\",\"reg:linear\",\"--subsample\",\"0.7\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[35mSM_HP_MAX_DEPTH=5\u001b[0m\n",
      "\u001b[35mSM_HP_MIN_CHILD_WEIGHT=6\u001b[0m\n",
      "\u001b[35mSM_HP_OBJECTIVE=reg:linear\u001b[0m\n",
      "\u001b[35mSM_HP_SUBSAMPLE=0.7\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m script --eta 0.2 --max_depth 5 --min_child_weight 6 --objective reg:linear --subsample 0.7\u001b[0m\n",
      "\u001b[35mCollecting sagemaker\n",
      "  Downloading sagemaker-2.169.0.tar.gz (851 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 851.8/851.8 kB 61.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting ray\n",
      "  Downloading ray-2.5.1-cp38-cp38-manylinux2014_x86_64.whl (56.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting ray\n",
      "  Downloading ray-2.5.1-cp38-cp38-manylinux2014_x86_64.whl (56.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 38.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting xgboost_ray\n",
      "  Downloading xgboost_ray-0.1.16-py3-none-any.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 36.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=6.0.1\n",
      "  Downloading pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\u001b[0m\n",
      "\u001b[35m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 36.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting xgboost_ray\n",
      "  Downloading xgboost_ray-0.1.16-py3-none-any.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 44.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pyarrow>=6.0.1\n",
      "  Downloading pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.0/39.0 MB 49.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.0/39.0 MB 49.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 21.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.131 (from sagemaker)\n",
      "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.9/135.9 kB 36.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting google-pasta (from sagemaker)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 19.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5 (from sagemaker)\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 18.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting boto3<2.0,>=1.26.131 (from sagemaker)\n",
      "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.9/135.9 kB 38.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: cloudpickle==2.2.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (2.2.1)\u001b[0m\n",
      "\u001b[35mCollecting google-pasta (from sagemaker)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 15.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[35mCollecting protobuf3-to-dict<1.0,>=0.1.5 (from sagemaker)\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting smdebug_rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[35mCollecting importlib-metadata<5.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (23.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[35mCollecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 15.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35mCollecting PyYAML==6.0 (from sagemaker)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 74.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting jsonschema (from sagemaker)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 23.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting platformdirs (from sagemaker)\n",
      "  Downloading platformdirs-3.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tblib==1.7.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.7.0)\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 23.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting PyYAML==6.0 (from sagemaker)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 83.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jsonschema (from sagemaker)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 21.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting platformdirs (from sagemaker)\n",
      "  Downloading platformdirs-3.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib==1.7.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /miniconda3/lib/python3.8/site-packages (from ray) (8.1.3)\u001b[0m\n",
      "\u001b[34mCollecting filelock (from ray)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /miniconda3/lib/python3.8/site-packages (from ray) (1.0.5)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal (from ray)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist (from ray)\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 44.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from ray) (2.25.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: click>=7.0 in /miniconda3/lib/python3.8/site-packages (from ray) (8.1.3)\u001b[0m\n",
      "\u001b[35mCollecting filelock (from ray)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /miniconda3/lib/python3.8/site-packages (from ray) (1.0.5)\u001b[0m\n",
      "\u001b[35mCollecting aiosignal (from ray)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[35mCollecting frozenlist (from ray)\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 46.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from ray) (2.25.1)\u001b[0m\n",
      "\u001b[35mCollecting grpcio<=1.51.3,>=1.32.0 (from ray)\n",
      "  Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 53.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio<=1.51.3,>=1.32.0 (from ray)\n",
      "  Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 72.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.12.1 (from xgboost_ray)\n",
      "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 kB 26.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xgboost>=0.90 in /miniconda3/lib/python3.8/site-packages (from xgboost_ray) (1.7.4)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.31.0,>=1.30.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\u001b[0m\n",
      "\u001b[35mCollecting wrapt>=1.12.1 (from xgboost_ray)\n",
      "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 kB 28.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: xgboost>=0.90 in /miniconda3/lib/python3.8/site-packages (from xgboost_ray) (1.7.4)\u001b[0m\n",
      "\u001b[35mCollecting botocore<1.31.0,>=1.30.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 102.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[35mCollecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 25.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from xgboost>=0.90->xgboost_ray) (1.6.2)\u001b[0m\n",
      "\u001b[35mCollecting importlib-resources>=1.4.0 (from jsonschema->sagemaker)\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[35mCollecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker)\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 135.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 24.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from xgboost>=0.90->xgboost_ray) (1.6.2)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=1.4.0 (from jsonschema->sagemaker)\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker)\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema->sagemaker)\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 21.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2023.3)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 14.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6 (from pathos->sagemaker)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 39.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14 (from pathos->sagemaker)\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 33.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (1.26.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2023.5.7)\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5 (from schema->sagemaker)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[35mCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema->sagemaker)\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 20.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2023.3)\u001b[0m\n",
      "\u001b[35mCollecting ppft>=1.7.6.6 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 19.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting dill>=0.3.6 (from pathos->sagemaker)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pox>=0.3.2 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[35mCollecting multiprocess>=0.70.14 (from pathos->sagemaker)\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 31.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: chardet<5,>=3.0.2 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (4.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<3,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2.10)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (1.26.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2023.5.7)\u001b[0m\n",
      "\u001b[35mCollecting contextlib2>=0.5.5 (from schema->sagemaker)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.169.0-py2.py3-none-any.whl size=1158254 sha256=102cf0b5f329d127d945f503e76de816764be0528ee5e8470aa77e1935c675f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/8a/77/1f49ecc28c3dfb9c082a3789111b0c96d4cd8ee8e172450655\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=43a4a9fa4235c53a3a9b8718b1a6a723986a29e2886d7b7a320a355e37e1fa51\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[35m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.169.0-py2.py3-none-any.whl size=1158254 sha256=102cf0b5f329d127d945f503e76de816764be0528ee5e8470aa77e1935c675f7\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/8a/77/1f49ecc28c3dfb9c082a3789111b0c96d4cd8ee8e172450655\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=43a4a9fa4235c53a3a9b8718b1a6a723986a29e2886d7b7a320a355e37e1fa51\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[35mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[35mInstalling collected packages: wrapt, smdebug_rulesconfig, PyYAML, pyrsistent, pyarrow, protobuf3-to-dict, ppft, pox, platformdirs, pkgutil-resolve-name, importlib-resources, importlib-metadata, grpcio, google-pasta, frozenlist, filelock, dill, contextlib2, attrs, schema, multiprocess, jsonschema, botocore, aiosignal, s3transfer, ray, pathos, xgboost_ray, boto3, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\u001b[0m\n",
      "\u001b[34mInstalling collected packages: wrapt, smdebug_rulesconfig, PyYAML, pyrsistent, pyarrow, protobuf3-to-dict, ppft, pox, platformdirs, pkgutil-resolve-name, importlib-resources, importlib-metadata, grpcio, google-pasta, frozenlist, filelock, dill, contextlib2, attrs, schema, multiprocess, jsonschema, botocore, aiosignal, s3transfer, ray, pathos, xgboost_ray, boto3, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 1.0.1\n",
      "    Uninstalling pyarrow-1.0.1:\n",
      "      Successfully uninstalled pyarrow-1.0.1\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 1.0.1\n",
      "    Uninstalling pyarrow-1.0.1:\n",
      "      Successfully uninstalled pyarrow-1.0.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\u001b[35mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[35msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.27.0 which is incompatible.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.30.0 which is incompatible.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires PyYAML==5.4.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[35mSuccessfully installed PyYAML-6.0 aiosignal-1.3.1 attrs-23.1.0 boto3-1.27.0 botocore-1.30.0 contextlib2-21.6.0 dill-0.3.6 filelock-3.12.2 frozenlist-1.3.3 google-pasta-0.2.0 grpcio-1.51.3 importlib-metadata-4.13.0 importlib-resources-5.12.0 jsonschema-4.17.3 multiprocess-0.70.14 pathos-0.3.0 pkgutil-resolve-name-1.3.10 platformdirs-3.8.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyarrow-12.0.1 pyrsistent-0.19.3 ray-2.5.1 s3transfer-0.6.1 sagemaker-2.169.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 wrapt-1.15.0 xgboost_ray-0.1.16\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.27.0 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.30.0 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires PyYAML==5.4.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyYAML-6.0 aiosignal-1.3.1 attrs-23.1.0 boto3-1.27.0 botocore-1.30.0 contextlib2-21.6.0 dill-0.3.6 filelock-3.12.2 frozenlist-1.3.3 google-pasta-0.2.0 grpcio-1.51.3 importlib-metadata-4.13.0 importlib-resources-5.12.0 jsonschema-4.17.3 multiprocess-0.70.14 pathos-0.3.0 pkgutil-resolve-name-1.3.10 platformdirs-3.8.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyarrow-12.0.1 pyrsistent-0.19.3 ray-2.5.1 s3transfer-0.6.1 sagemaker-2.169.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 wrapt-1.15.0 xgboost_ray-0.1.16\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:05,127#011INFO usage_lib.py:408 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:05,128#011INFO scripts.py:712 -- Local node IP: 10.0.81.246\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011SUCC scripts.py:749 -- --------------------\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011SUCC scripts.py:750 -- Ray runtime started.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011SUCC scripts.py:751 -- --------------------\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:753 -- Next steps\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:756 -- To add another node to this Ray cluster, run\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:759 --   ray start --address='10.0.81.246:9339'\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:768 -- To connect to this Ray cluster:\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:770 -- import ray\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,664#011INFO scripts.py:771 -- ray.init()\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,665#011INFO scripts.py:802 -- To terminate the Ray runtime, run\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,665#011INFO scripts.py:803 --   ray stop\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,665#011INFO scripts.py:806 -- To view the status of the cluster, use\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,665#011INFO scripts.py:807 --   ray status\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,729#011INFO worker.py:1452 -- Connecting to existing Ray cluster at address: 10.0.81.246:9339...\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:06,734#011INFO worker.py:1636 -- Connected to Ray cluster.\u001b[0m\n",
      "\u001b[34mWaiting 60 seconds for 2 nodes to join\u001b[0m\n",
      "\u001b[34m1 nodes connected to cluster\u001b[0m\n",
      "\u001b[34m1 nodes connected to cluster\u001b[0m\n",
      "\u001b[35m[2023-07-04 20:40:15,414 I 92 92] global_state_accessor.cc:356: This node has an IP address of 10.0.106.43, but we cannot find a local Raylet with the same address. This can happen when you connect to the Ray cluster with a different IP address or when connecting to a container.\u001b[0m\n",
      "\u001b[34mAll workers present and accounted for\u001b[0m\n",
      "\u001b[34m{'CPU': 16.0, 'node:10.0.81.246': 1.0, 'object_store_memory': 8127859506.0, 'memory': 17611069851.0, 'node:10.0.106.43': 1.0}\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:241: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   pq_ds.pieces, **prefetch_remote_args\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:324: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   num_files = len(self._pq_ds.pieces)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:337: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   self._pq_ds.pieces[idx]\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:271: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   np.array_split(self._pq_ds.pieces, parallelism),\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,057#011WARNING dataset.py:253 -- #033[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\u001b[0m\n",
      "\u001b[34mLearn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,085#011INFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->MapBatches(<lambda>)]\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,085#011INFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,085#011INFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\u001b[0m\n",
      "\u001b[34m[dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,284#011INFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-9, stopped daemon 139895173531392)>.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train count is 6000\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,434#011INFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->MapBatches(<lambda>)]\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,434#011INFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,434#011INFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,693#011INFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-12, stopped daemon 139895565694720)>.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation count is 2000\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,774#011INFO tensorboardx.py:178 -- pip install \"ray[tune]\" to see TensorBoard files.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:20,774#011WARNING callback.py:144 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:40:20 (running for 00:00:00.11)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-40-20\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 PENDING)\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status   | loc   |\u001b[0m\n",
      "\u001b[34m|----------------------------+----------+-------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_fe449_00000 | PENDING  |       |\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=1205)#033[0m 2023-07-04 20:40:23,441#011WARNING dataset.py:253 -- #033[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=1205)#033[0m \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=1205)#033[0m Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:271: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead#033[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_RemoteRayXGBoostActor pid=852, ip=10.0.106.43)#033[0m [20:40:24] task [xgboost.ray]:139986766218528 got new rank 0\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m [20:40:24] task [xgboost.ray]:139817232385408 got new rank 1\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m [20:40:24] task [xgboost.ray]:139817232385408 got new rank 1\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m [20:40:24] task [xgboost.ray]:139817232385408 got new rank 1\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:40:25 (running for 00:00:05.14)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-40-20\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+------------------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status   | loc              |\u001b[0m\n",
      "\u001b[34m|----------------------------+----------+------------------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_fe449_00000 | RUNNING  | 10.0.81.246:1205 |\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+------------------+\u001b[0m\n",
      "\u001b[34mResult for XGBoostTrainer_fe449_00000:\n",
      "  date: 2023-07-04_20-40-27\n",
      "  done: false\n",
      "  hostname: ip-10-0-81-246.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.81.246\n",
      "  pid: 1205\n",
      "  time_since_restore: 5.206688165664673\n",
      "  time_this_iter_s: 5.206688165664673\n",
      "  time_total_s: 5.206688165664673\n",
      "  timestamp: 1688503227\n",
      "  train-mae: 347408.36672395834\n",
      "  train-rmse: 362105.3488793006\n",
      "  training_iteration: 1\n",
      "  trial_id: fe449_00000\n",
      "  valid-mae: 349256.6527895083\n",
      "  valid-rmse: 363794.79333687417\n",
      "  \u001b[0m\n",
      "\u001b[34mResult for XGBoostTrainer_fe449_00000:\n",
      "  date: 2023-07-04_20-40-27\n",
      "  done: true\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-81-246.ec2.internal\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 10.0.81.246\n",
      "  pid: 1205\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.623102426528931\n",
      "  time_this_iter_s: 0.014942646026611328\n",
      "  time_total_s: 5.623102426528931\n",
      "  timestamp: 1688503227\n",
      "  train-mae: 3933.844333496094\n",
      "  train-rmse: 5099.151466698762\n",
      "  training_iteration: 101\n",
      "  trial_id: fe449_00000\n",
      "  valid-mae: 4969.9406144425675\n",
      "  valid-rmse: 6470.111499401678\n",
      "  \u001b[0m\n",
      "\u001b[34mTrial XGBoostTrainer_fe449_00000 completed.\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:40:27 (running for 00:00:07.17)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-40-20\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 TERMINATED)\u001b[0m\n",
      "\u001b[34m+----------------------------+------------+------------------+--------+------------------+-------------+--------------+-------------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status     | loc              |   iter |   total time (s) |   train-mae |   train-rmse |   valid-mae |\u001b[0m\n",
      "\u001b[34m|----------------------------+------------+------------------+--------+------------------+-------------+--------------+-------------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_fe449_00000 | TERMINATED | 10.0.81.246:1205 |    101 |           5.6231 |     3933.84 |      5099.15 |     4969.94 |\u001b[0m\n",
      "\u001b[34m+----------------------------+------------+------------------+--------+------------------+-------------+--------------+-------------+\u001b[0m\n",
      "\u001b[34m2023-07-04 20:40:27,949#011INFO tune.py:1111 -- Total run time: 7.20 seconds (7.17 seconds for the tuning loop).\u001b[0m\n",
      "\u001b[34m<==== Start Training Metrics ====>\u001b[0m\n",
      "\u001b[34m{'train-mae': 3933.844333496094, 'train-rmse': 5099.151466698762, 'valid-mae': 4969.9406144425675, 'valid-rmse': 6470.111499401678, 'time_this_iter_s': 0.014942646026611328, 'should_checkpoint': True, 'done': True, 'training_iteration': 101, 'trial_id': 'fe449_00000', 'date': '2023-07-04_20-40-27', 'timestamp': 1688503227, 'time_total_s': 5.623102426528931, 'pid': 1205, 'hostname': 'ip-10-0-81-246.ec2.internal', 'node_ip': '10.0.81.246', 'config': {}, 'time_since_restore': 5.623102426528931, 'iterations_since_restore': 101, 'experiment_tag': '0'}\u001b[0m\n",
      "\u001b[34m<==== END Training Metrics ====>\u001b[0m\n",
      "\u001b[34m[1] #011train-mae:3933.844333496094\u001b[0m\n",
      "\u001b[34m[2] #011train-rmse:5099.151466698762\u001b[0m\n",
      "\u001b[34m[3] #011validation-mae:4969.9406144425675\u001b[0m\n",
      "\u001b[34m[4] #011validation-rmse:6470.111499401678\u001b[0m\n",
      "\u001b[34mINFO:sagemaker.experiments.run:The run (xgboost-run) under experiment (synthetic-housing-xgb-regression-1688503056-2258) already exists. Loading it.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker.experiments.run:The run (xgboost-run) under experiment (synthetic-housing-xgb-regression-1688503056-2258) already exists. Loading it.\u001b[0m\n",
      "\u001b[34mTOTAL TIME TAKEN: 13.70 seconds\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=244)#033[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_RemoteRayXGBoostActor pid=854, ip=10.0.106.43)#033[0m [20:40:25] task [xgboost.ray]:140317388797264 got new rank 2#033[32m [repeated 2x across cluster]#033[0m\u001b[0m\n",
      "\n",
      "2023-07-04 20:41:38 Uploading - Uploading generated training model\n",
      "2023-07-04 20:41:49 Completed - Training job completed\n",
      "Training seconds: 356\n",
      "Billable seconds: 356\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(\n",
    "            region, experiment_name\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "with Run(experiment_name=experiment_name, run_name='XGBoost-run') as run:\n",
    "    estimator = XGBoost(**estimator_parameters)\n",
    "    estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f9fb4e-f6eb-44e4-a305-58e03eef3475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"max_depth\": IntegerParameter(1, 8),\n",
    "    \"eta\": ContinuousParameter(0.2, 1),\n",
    "    \"min_child_weight\": IntegerParameter(0, 120),\n",
    "    \"subsample\": ContinuousParameter(0.2, 1),\n",
    "}\n",
    "\n",
    "objective_metric_name = 'validation:rmse'\n",
    "objective_type = 'Minimize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ecf73a3-11a9-4944-afd7-d5e5ae6c02cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs/xgb-model-tuning-04-20-42-28\">Tuning Job</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgb-model-tuning-04-20-42-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuner_parameters = {\n",
    "                    'estimator': estimator,\n",
    "                    'objective_metric_name': objective_metric_name,\n",
    "                    'hyperparameter_ranges': hyperparameter_ranges,\n",
    "                    # 'metric_definitions': metric_definitions,\n",
    "                    'max_jobs': 4,\n",
    "                    'max_parallel_jobs': 2,\n",
    "                    'objective_type': objective_type\n",
    "                    }\n",
    "    \n",
    "tuner = HyperparameterTuner(**tuner_parameters)\n",
    "\n",
    "tuning_job_name = f'xgb-model-tuning-{strftime(\"%d-%H-%M-%S\", gmtime())}'\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review the <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\">Tuning Job</a> After About 5 Minutes</b>'.format(\n",
    "            region, tuning_job_name\n",
    "        )\n",
    "    )\n",
    ")\n",
    "tuner.fit(inputs, job_name=tuning_job_name)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2057a48-10cd-44b4-966f-60ba94ec6065",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>subsample</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389778</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.732408</td>\n",
       "      <td>xgb-model-tuning-04-20-42-28-002-7dbed3fb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>10061.348633</td>\n",
       "      <td>2023-07-04 20:43:42+00:00</td>\n",
       "      <td>2023-07-04 20:46:35+00:00</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294678</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>xgb-model-tuning-04-20-42-28-001-08d509b3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>10950.479492</td>\n",
       "      <td>2023-07-04 20:43:39+00:00</td>\n",
       "      <td>2023-07-04 20:46:37+00:00</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876835</td>\n",
       "      <td>7.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.961943</td>\n",
       "      <td>xgb-model-tuning-04-20-42-28-004-c028b040</td>\n",
       "      <td>Completed</td>\n",
       "      <td>13059.387695</td>\n",
       "      <td>2023-07-04 20:47:54+00:00</td>\n",
       "      <td>2023-07-04 20:50:02+00:00</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.732445</td>\n",
       "      <td>xgb-model-tuning-04-20-42-28-003-51e7aefc</td>\n",
       "      <td>Completed</td>\n",
       "      <td>15361.978516</td>\n",
       "      <td>2023-07-04 20:47:02+00:00</td>\n",
       "      <td>2023-07-04 20:49:15+00:00</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        eta  max_depth  min_child_weight  subsample  \\\n",
       "2  0.389778        7.0              65.0   0.732408   \n",
       "3  0.294678        4.0              40.0   0.302141   \n",
       "0  0.876835        7.0             118.0   0.961943   \n",
       "1  0.589236        1.0              89.0   0.732445   \n",
       "\n",
       "                             TrainingJobName TrainingJobStatus  \\\n",
       "2  xgb-model-tuning-04-20-42-28-002-7dbed3fb         Completed   \n",
       "3  xgb-model-tuning-04-20-42-28-001-08d509b3         Completed   \n",
       "0  xgb-model-tuning-04-20-42-28-004-c028b040         Completed   \n",
       "1  xgb-model-tuning-04-20-42-28-003-51e7aefc         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "2         10061.348633 2023-07-04 20:43:42+00:00 2023-07-04 20:46:35+00:00   \n",
       "3         10950.479492 2023-07-04 20:43:39+00:00 2023-07-04 20:46:37+00:00   \n",
       "0         13059.387695 2023-07-04 20:47:54+00:00 2023-07-04 20:50:02+00:00   \n",
       "1         15361.978516 2023-07-04 20:47:02+00:00 2023-07-04 20:49:15+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "2                       173.0  \n",
       "3                       178.0  \n",
       "0                       128.0  \n",
       "1                       133.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)\n",
    "tuner_metrics.dataframe().sort_values(['FinalObjectiveValue'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61167130-646f-4797-90f0-16662f9e48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = 'synthetic-housing-models-ray'\n",
    "#model_package_group_name = unique_name_from_base('synthetic-housing-models-ray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df9a7b71-757d-49c1-b8e4-9338a3d472e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupArn': 'arn:aws:sagemaker:us-east-1:523914011708:model-package-group/synthetic-housing-models-ray-1688505916-5329',\n",
       " 'ResponseMetadata': {'RequestId': 'acf58269-1e8d-4d23-b42d-c29fe9f2fcef',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'acf58269-1e8d-4d23-b42d-c29fe9f2fcef',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Tue, 04 Jul 2023 21:26:13 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_client.create_model_package_group(ModelPackageGroupName=model_package_group_name,\n",
    "                                            ModelPackageGroupDescription='Models predicting synthetic housing prices')                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf3f3c1-e8d8-4f2f-9f75-8690e35cb742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.2xlarge.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-04 20:47:01 Starting - Preparing the instances for training\n",
      "2023-07-04 20:47:01 Downloading - Downloading input data\n",
      "2023-07-04 20:47:01 Training - Training image download completed. Training in progress.\n",
      "2023-07-04 20:47:01 Uploading - Uploading generated training model\n",
      "2023-07-04 20:47:01 Completed - Resource reused by training job: xgb-model-tuning-04-20-42-28-003-51e7aefc\u001b[34m[2023-07-04 20:44:34.527 ip-10-0-76-161.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-07-04 20:44:34.549 ip-10-0-76-161.ec2.internal:7 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:34:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:34:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:rmse to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:34:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:35:INFO] Module script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:35:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:35:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:35:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35m[2023-07-04 20:44:34.204 ip-10-0-89-86.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2023-07-04 20:44:34.227 ip-10-0-89-86.ec2.internal:7 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:rmse to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Module script does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:34:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: script\n",
      "  Building wheel for script (setup.py): started\n",
      "  Building wheel for script (setup.py): finished with status 'done'\n",
      "  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=12785 sha256=21f50263998a631261f7b074c101dd474773c89843ba62c6b87e0c0c336bdc9b\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-4ipgciay/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35mSuccessfully built script\u001b[0m\n",
      "\u001b[35mInstalling collected packages: script\u001b[0m\n",
      "\u001b[35mSuccessfully installed script-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:35:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:rmse to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2023-07-04:20:44:35:INFO] Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_class_name\": \"XGBoost\",\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.xgboost.estimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.38977766201396086,\n",
      "        \"max_depth\": 7,\n",
      "        \"min_child_weight\": 65,\n",
      "        \"objective\": \"reg:linear\",\n",
      "        \"subsample\": 0.7324083691081733\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"xgb-model-tuning-04-20-42-28-002-7dbed3fb\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"eta\":0.38977766201396086,\"max_depth\":7,\"min_child_weight\":65,\"objective\":\"reg:linear\",\"subsample\":0.7324083691081733}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":0.38977766201396086,\"max_depth\":7,\"min_child_weight\":65,\"objective\":\"reg:linear\",\"subsample\":0.7324083691081733},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"xgb-model-tuning-04-20-42-28-002-7dbed3fb\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--eta\",\"0.38977766201396086\",\"--max_depth\",\"7\",\"--min_child_weight\",\"65\",\"--objective\",\"reg:linear\",\"--subsample\",\"0.7324083691081733\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35mSM_HP_ETA=0.38977766201396086\u001b[0m\n",
      "\u001b[35mSM_HP_MAX_DEPTH=7\u001b[0m\n",
      "\u001b[35mSM_HP_MIN_CHILD_WEIGHT=65\u001b[0m\n",
      "\u001b[35mSM_HP_OBJECTIVE=reg:linear\u001b[0m\n",
      "\u001b[35mSM_HP_SUBSAMPLE=0.7324083691081733\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m script --eta 0.38977766201396086 --max_depth 7 --min_child_weight 65 --objective reg:linear --subsample 0.7324083691081733\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: script\n",
      "  Building wheel for script (setup.py): started\n",
      "  Building wheel for script (setup.py): finished with status 'done'\n",
      "  Created wheel for script: filename=script-1.0.0-py2.py3-none-any.whl size=12785 sha256=21f50263998a631261f7b074c101dd474773c89843ba62c6b87e0c0c336bdc9b\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-9_7g7ls6/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built script\u001b[0m\n",
      "\u001b[34mInstalling collected packages: script\u001b[0m\n",
      "\u001b[34mSuccessfully installed script-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mCollecting sagemaker\n",
      "  Downloading sagemaker-2.169.0.tar.gz (851 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 851.8/851.8 kB 70.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting ray\n",
      "  Downloading ray-2.5.1-cp38-cp38-manylinux2014_x86_64.whl (56.3 MB)\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:36:INFO] Failed to parse hyperparameter _tuning_objective_metric value validation:rmse to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-07-04:20:44:36:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_class_name\": \"XGBoost\",\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.xgboost.estimator\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": 0.38977766201396086,\n",
      "        \"max_depth\": 7,\n",
      "        \"min_child_weight\": 65,\n",
      "        \"objective\": \"reg:linear\",\n",
      "        \"subsample\": 0.7324083691081733\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgb-model-tuning-04-20-42-28-002-7dbed3fb\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":0.38977766201396086,\"max_depth\":7,\"min_child_weight\":65,\"objective\":\"reg:linear\",\"subsample\":0.7324083691081733}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"XGBoost\",\"sagemaker_estimator_module\":\"sagemaker.xgboost.estimator\"},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"eta\":0.38977766201396086,\"max_depth\":7,\"min_child_weight\":65,\"objective\":\"reg:linear\",\"subsample\":0.7324083691081733},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgb-model-tuning-04-20-42-28-002-7dbed3fb\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-523914011708/xgb-model-tuning-04-20-42-28/source/sourcedir.tar.gz\",\"module_name\":\"script\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.38977766201396086\",\"--max_depth\",\"7\",\"--min_child_weight\",\"65\",\"--objective\",\"reg:linear\",\"--subsample\",\"0.7324083691081733\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.38977766201396086\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=7\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_CHILD_WEIGHT=65\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=reg:linear\u001b[0m\n",
      "\u001b[34mSM_HP_SUBSAMPLE=0.7324083691081733\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m script --eta 0.38977766201396086 --max_depth 7 --min_child_weight 65 --objective reg:linear --subsample 0.7324083691081733\u001b[0m\n",
      "\u001b[34mCollecting sagemaker\n",
      "  Downloading sagemaker-2.169.0.tar.gz (851 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 851.8/851.8 kB 49.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 39.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting xgboost_ray\n",
      "  Downloading xgboost_ray-0.1.16-py3-none-any.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 47.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pyarrow>=6.0.1\n",
      "  Downloading pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.0/39.0 MB 46.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting ray\n",
      "  Downloading ray-2.5.1-cp38-cp38-manylinux2014_x86_64.whl (56.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 36.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting xgboost_ray\n",
      "  Downloading xgboost_ray-0.1.16-py3-none-any.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 35.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=6.0.1\n",
      "  Downloading pyarrow-12.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\u001b[0m\n",
      "\u001b[35mCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 16.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting boto3<2.0,>=1.26.131 (from sagemaker)\n",
      "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.9/135.9 kB 35.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: cloudpickle==2.2.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (2.2.1)\u001b[0m\n",
      "\u001b[35mCollecting google-pasta (from sagemaker)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 15.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[35mCollecting protobuf3-to-dict<1.0,>=0.1.5 (from sagemaker)\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCollecting smdebug_rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[35mCollecting importlib-metadata<5.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (23.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[35mCollecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35mCollecting PyYAML==6.0 (from sagemaker)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 87.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting jsonschema (from sagemaker)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 31.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting platformdirs (from sagemaker)\n",
      "  Downloading platformdirs-3.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tblib==1.7.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.7.0)\u001b[0m\n",
      "\u001b[34m     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.0/39.0 MB 46.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 19.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting boto3<2.0,>=1.26.131 (from sagemaker)\n",
      "  Downloading boto3-1.27.0-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.9/135.9 kB 37.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting google-pasta (from sagemaker)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 19.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.9.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0,>=3.1 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (3.20.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf3-to-dict<1.0,>=0.1.5 (from sagemaker)\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: click>=7.0 in /miniconda3/lib/python3.8/site-packages (from ray) (8.1.3)\u001b[0m\n",
      "\u001b[35mCollecting filelock (from ray)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /miniconda3/lib/python3.8/site-packages (from ray) (1.0.5)\u001b[0m\n",
      "\u001b[35mCollecting aiosignal (from ray)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[35mCollecting frozenlist (from ray)\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 47.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from ray) (2.25.1)\u001b[0m\n",
      "\u001b[35mCollecting grpcio<=1.51.3,>=1.32.0 (from ray)\n",
      "  Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 113.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting wrapt>=1.12.1 (from xgboost_ray)\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting smdebug_rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting importlib-metadata<5.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.2.4)\u001b[0m\n",
      "\u001b[34mCollecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 26.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting PyYAML==6.0 (from sagemaker)\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 81.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jsonschema (from sagemaker)\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 kB 28.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting platformdirs (from sagemaker)\n",
      "  Downloading platformdirs-3.8.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib==1.7.0 in /miniconda3/lib/python3.8/site-packages (from sagemaker) (1.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /miniconda3/lib/python3.8/site-packages (from ray) (8.1.3)\u001b[0m\n",
      "\u001b[34mCollecting filelock (from ray)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /miniconda3/lib/python3.8/site-packages (from ray) (1.0.5)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal (from ray)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist (from ray)\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 41.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from ray) (2.25.1)\u001b[0m\n",
      "\u001b[35m  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 kB 25.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: xgboost>=0.90 in /miniconda3/lib/python3.8/site-packages (from xgboost_ray) (1.7.4)\u001b[0m\n",
      "\u001b[35mCollecting botocore<1.31.0,>=1.30.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 134.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[35mCollecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 28.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from xgboost>=0.90->xgboost_ray) (1.6.2)\u001b[0m\n",
      "\u001b[35mCollecting importlib-resources>=1.4.0 (from jsonschema->sagemaker)\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[35mCollecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker)\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[35mCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema->sagemaker)\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 20.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2023.3)\u001b[0m\n",
      "\u001b[35mCollecting ppft>=1.7.6.6 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 18.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting dill>=0.3.6 (from pathos->sagemaker)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 41.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pox>=0.3.2 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[35mCollecting multiprocess>=0.70.14 (from pathos->sagemaker)\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 41.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting grpcio<=1.51.3,>=1.32.0 (from ray)\n",
      "  Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 62.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.12.1 (from xgboost_ray)\n",
      "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 kB 24.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xgboost>=0.90 in /miniconda3/lib/python3.8/site-packages (from xgboost_ray) (1.7.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: chardet<5,>=3.0.2 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (4.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<3,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2.10)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (1.26.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2023.5.7)\u001b[0m\n",
      "\u001b[35mCollecting contextlib2>=0.5.5 (from schema->sagemaker)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.169.0-py2.py3-none-any.whl size=1158254 sha256=0d02260b12683209e51282b1a4cad0512253087427c1894d5c160845cb1d527a\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/8a/77/1f49ecc28c3dfb9c082a3789111b0c96d4cd8ee8e172450655\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.31.0,>=1.30.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading botocore-1.30.0-py3-none-any.whl (11.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.0/11.0 MB 116.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.7.0,>=0.6.0 (from boto3<2.0,>=1.26.131->sagemaker)\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 20.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /miniconda3/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /miniconda3/lib/python3.8/site-packages (from xgboost>=0.90->xgboost_ray) (1.6.2)\u001b[0m\n",
      "\u001b[34mCollecting importlib-resources>=1.4.0 (from jsonschema->sagemaker)\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mCollecting pkgutil-resolve-name>=1.3.10 (from jsonschema->sagemaker)\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema->sagemaker)\n",
      "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 16.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /miniconda3/lib/python3.8/site-packages (from pandas->sagemaker) (2023.3)\u001b[0m\n",
      "\u001b[34mCollecting ppft>=1.7.6.6 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.6-py3-none-any.whl (52 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.8/52.8 kB 15.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting dill>=0.3.6 (from pathos->sagemaker)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 35.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pox>=0.3.2 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.2-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess>=0.70.14 (from pathos->sagemaker)\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 40.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (4.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (1.26.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->ray) (2023.5.7)\u001b[0m\n",
      "\u001b[34mCollecting contextlib2>=0.5.5 (from schema->sagemaker)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[35m  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=2d8cb8a38f4da2c90ca440f9fc1025750324d746ca43540ee5b28ab978ec65c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[35mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[35mInstalling collected packages: wrapt, smdebug_rulesconfig, PyYAML, pyrsistent, pyarrow, protobuf3-to-dict, ppft, pox, platformdirs, pkgutil-resolve-name, importlib-resources, importlib-metadata, grpcio, google-pasta, frozenlist, filelock, dill, contextlib2, attrs, schema, multiprocess, jsonschema, botocore, aiosignal, s3transfer, ray, pathos, xgboost_ray, boto3, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 1.0.1\n",
      "    Uninstalling pyarrow-1.0.1:\n",
      "      Successfully uninstalled pyarrow-1.0.1\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.169.0-py2.py3-none-any.whl size=1158254 sha256=985cecc8d91744abcaaa4a3881eb294b8f41e46390c822313fc59c04ca9f32c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/dc/8a/77/1f49ecc28c3dfb9c082a3789111b0c96d4cd8ee8e172450655\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4014 sha256=2d8cb8a38f4da2c90ca440f9fc1025750324d746ca43540ee5b28ab978ec65c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/10/27/2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker protobuf3-to-dict\u001b[0m\n",
      "\u001b[34mInstalling collected packages: wrapt, smdebug_rulesconfig, PyYAML, pyrsistent, pyarrow, protobuf3-to-dict, ppft, pox, platformdirs, pkgutil-resolve-name, importlib-resources, importlib-metadata, grpcio, google-pasta, frozenlist, filelock, dill, contextlib2, attrs, schema, multiprocess, jsonschema, botocore, aiosignal, s3transfer, ray, pathos, xgboost_ray, boto3, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 1.0.1\n",
      "    Uninstalling pyarrow-1.0.1:\n",
      "      Successfully uninstalled pyarrow-1.0.1\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.6.0\n",
      "    Uninstalling importlib-metadata-6.6.0:\n",
      "      Successfully uninstalled importlib-metadata-6.6.0\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.52\n",
      "    Uninstalling botocore-1.20.52:\n",
      "      Successfully uninstalled botocore-1.20.52\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.3.7\n",
      "    Uninstalling s3transfer-0.3.7:\n",
      "      Successfully uninstalled s3transfer-0.3.7\u001b[0m\n",
      "\u001b[35m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\u001b[35mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[35msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.27.0 which is incompatible.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.30.0 which is incompatible.\u001b[0m\n",
      "\u001b[35msagemaker-xgboost-container 2.0 requires PyYAML==5.4.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[35mSuccessfully installed PyYAML-6.0 aiosignal-1.3.1 attrs-23.1.0 boto3-1.27.0 botocore-1.30.0 contextlib2-21.6.0 dill-0.3.6 filelock-3.12.2 frozenlist-1.3.3 google-pasta-0.2.0 grpcio-1.51.3 importlib-metadata-4.13.0 importlib-resources-5.12.0 jsonschema-4.17.3 multiprocess-0.70.14 pathos-0.3.0 pkgutil-resolve-name-1.3.10 platformdirs-3.8.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyarrow-12.0.1 pyrsistent-0.19.3 ray-2.5.1 s3transfer-0.6.1 sagemaker-2.169.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 wrapt-1.15.0 xgboost_ray-0.1.16\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.52\n",
      "    Uninstalling boto3-1.17.52:\n",
      "      Successfully uninstalled boto3-1.17.52\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-containers 2.8.6.post2 requires typing, which is not installed.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires boto3==1.17.52, but you have boto3 1.27.0 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires botocore==1.20.52, but you have botocore 1.30.0 which is incompatible.\u001b[0m\n",
      "\u001b[34msagemaker-xgboost-container 2.0 requires PyYAML==5.4.1, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyYAML-6.0 aiosignal-1.3.1 attrs-23.1.0 boto3-1.27.0 botocore-1.30.0 contextlib2-21.6.0 dill-0.3.6 filelock-3.12.2 frozenlist-1.3.3 google-pasta-0.2.0 grpcio-1.51.3 importlib-metadata-4.13.0 importlib-resources-5.12.0 jsonschema-4.17.3 multiprocess-0.70.14 pathos-0.3.0 pkgutil-resolve-name-1.3.10 platformdirs-3.8.0 pox-0.3.2 ppft-1.7.6.6 protobuf3-to-dict-0.1.5 pyarrow-12.0.1 pyrsistent-0.19.3 ray-2.5.1 s3transfer-0.6.1 sagemaker-2.169.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 wrapt-1.15.0 xgboost_ray-0.1.16\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:51,953#011INFO usage_lib.py:408 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:51,954#011INFO scripts.py:712 -- Local node IP: 10.0.76.161\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,493#011SUCC scripts.py:749 -- --------------------\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,493#011SUCC scripts.py:750 -- Ray runtime started.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,493#011SUCC scripts.py:751 -- --------------------\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,493#011INFO scripts.py:753 -- Next steps\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:756 -- To add another node to this Ray cluster, run\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:759 --   ray start --address='10.0.76.161:9339'\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:768 -- To connect to this Ray cluster:\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:770 -- import ray\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:771 -- ray.init()\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:802 -- To terminate the Ray runtime, run\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:803 --   ray stop\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:806 -- To view the status of the cluster, use\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,494#011INFO scripts.py:807 --   ray status\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,591#011INFO worker.py:1452 -- Connecting to existing Ray cluster at address: 10.0.76.161:9339...\u001b[0m\n",
      "\u001b[34m2023-07-04 20:44:53,596#011INFO worker.py:1636 -- Connected to Ray cluster.\u001b[0m\n",
      "\u001b[34mWaiting 60 seconds for 2 nodes to join\u001b[0m\n",
      "\u001b[34m1 nodes connected to cluster\u001b[0m\n",
      "\u001b[34m1 nodes connected to cluster\u001b[0m\n",
      "\u001b[35m[2023-07-04 20:45:00,722 I 92 92] global_state_accessor.cc:356: This node has an IP address of 10.0.89.86, but we cannot find a local Raylet with the same address. This can happen when you connect to the Ray cluster with a different IP address or when connecting to a container.\u001b[0m\n",
      "\u001b[34mAll workers present and accounted for\u001b[0m\n",
      "\u001b[34m{'object_store_memory': 8180646296.0, 'memory': 17726723279.0, 'node:10.0.76.161': 1.0, 'CPU': 16.0, 'node:10.0.89.86': 1.0}\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:241: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   pq_ds.pieces, **prefetch_remote_args\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:324: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   num_files = len(self._pq_ds.pieces)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:337: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   self._pq_ds.pieces[idx]\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:271: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=245)#033[0m   np.array_split(self._pq_ds.pieces, parallelism),\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:06,980#011WARNING dataset.py:253 -- #033[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\u001b[0m\n",
      "\u001b[34mLearn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,002#011INFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->MapBatches(<lambda>)]\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,002#011INFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,003#011INFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\u001b[0m\n",
      "\u001b[34m[dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,209#011INFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-9, stopped daemon 140161316796160)>.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/train count is 6000\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,355#011INFO streaming_executor.py:91 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet->MapBatches(<lambda>)]\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,355#011INFO streaming_executor.py:92 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,355#011INFO streaming_executor.py:94 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,500#011INFO streaming_executor.py:149 -- Shutting down <StreamingExecutor(Thread-12, stopped daemon 140161358755584)>.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/validation count is 2000\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,582#011INFO tensorboardx.py:178 -- pip install \"ray[tune]\" to see TensorBoard files.\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:07,582#011WARNING callback.py:144 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:45:07 (running for 00:00:00.11)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-45-07\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 PENDING)\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status   | loc   |\u001b[0m\n",
      "\u001b[34m|----------------------------+----------+-------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_a9381_00000 | PENDING  |       |\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+-------+\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=803, ip=10.0.89.86)#033[0m 2023-07-04 20:45:10,106#011WARNING dataset.py:253 -- #033[33mImportant: Ray Data requires schemas for all datasets in Ray 2.5. This means that standalone Python objects are no longer supported. In addition, the default batch format is fixed to NumPy. To revert to legacy behavior temporarily, set the environment variable RAY_DATA_STRICT_MODE=0 on all cluster processes.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=803, ip=10.0.89.86)#033[0m \u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(XGBoostTrainer pid=803, ip=10.0.89.86)#033[0m Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m /miniconda3/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py:271: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Use the '.fragments' attribute instead#033[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m Learn more here: https://docs.ray.io/en/master/data/faq.html#migrating-to-strict-mode#033[0m\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_RemoteRayXGBoostActor pid=1161)#033[0m [20:45:11] task [xgboost.ray]:140233014342800 got new rank 0\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:45:12 (running for 00:00:05.16)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-45-07\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 RUNNING)\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+----------------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status   | loc            |\u001b[0m\n",
      "\u001b[34m|----------------------------+----------+----------------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_a9381_00000 | RUNNING  | 10.0.89.86:803 |\u001b[0m\n",
      "\u001b[34m+----------------------------+----------+----------------+\u001b[0m\n",
      "\u001b[34mResult for XGBoostTrainer_a9381_00000:\n",
      "  date: 2023-07-04_20-45-13\n",
      "  done: false\n",
      "  hostname: ip-10-0-89-86.ec2.internal\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.89.86\n",
      "  pid: 803\n",
      "  time_since_restore: 4.798951625823975\n",
      "  time_this_iter_s: 4.798951625823975\n",
      "  time_total_s: 4.798951625823975\n",
      "  timestamp: 1688503513\n",
      "  train-mae: 265434.2160247396\n",
      "  train-rmse: 277789.99117984966\n",
      "  training_iteration: 1\n",
      "  trial_id: a9381_00000\n",
      "  valid-mae: 266501.2412647022\n",
      "  valid-rmse: 278873.0700940175\n",
      "  \u001b[0m\n",
      "\u001b[34mResult for XGBoostTrainer_a9381_00000:\n",
      "  date: 2023-07-04_20-45-14\n",
      "  done: true\n",
      "  experiment_tag: '0'\n",
      "  hostname: ip-10-0-89-86.ec2.internal\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 10.0.89.86\n",
      "  pid: 803\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.372997283935547\n",
      "  time_this_iter_s: 0.019658803939819336\n",
      "  time_total_s: 5.372997283935547\n",
      "  timestamp: 1688503514\n",
      "  train-mae: 5445.114716145833\n",
      "  train-rmse: 8167.234552483368\n",
      "  training_iteration: 101\n",
      "  trial_id: a9381_00000\n",
      "  valid-mae: 7012.789830846472\n",
      "  valid-rmse: 10061.348515050917\n",
      "  \u001b[0m\n",
      "\u001b[34mTrial XGBoostTrainer_a9381_00000 completed.\u001b[0m\n",
      "\u001b[34m== Status ==\u001b[0m\n",
      "\u001b[34mCurrent time: 2023-07-04 20:45:15 (running for 00:00:07.94)\u001b[0m\n",
      "\u001b[34mUsing FIFO scheduling algorithm.\u001b[0m\n",
      "\u001b[34mLogical resource usage: 3.0/16 CPUs, 0/0 GPUs\u001b[0m\n",
      "\u001b[34mResult logdir: /root/ray_results/XGBoostTrainer_2023-07-04_20-45-07\u001b[0m\n",
      "\u001b[34mNumber of trials: 1/1 (1 TERMINATED)\u001b[0m\n",
      "\u001b[34m+----------------------------+------------+----------------+--------+------------------+-------------+--------------+-------------+\u001b[0m\n",
      "\u001b[34m| Trial name                 | status     | loc            |   iter |   total time (s) |   train-mae |   train-rmse |   valid-mae |\u001b[0m\n",
      "\u001b[34m|----------------------------+------------+----------------+--------+------------------+-------------+--------------+-------------|\u001b[0m\n",
      "\u001b[34m| XGBoostTrainer_a9381_00000 | TERMINATED | 10.0.89.86:803 |    101 |            5.373 |     5445.11 |      8167.23 |     7012.79 |\u001b[0m\n",
      "\u001b[34m+----------------------------+------------+----------------+--------+------------------+-------------+--------------+-------------+\u001b[0m\n",
      "\u001b[34m2023-07-04 20:45:16,259#011INFO tune.py:1111 -- Total run time: 8.71 seconds (7.94 seconds for the tuning loop).\u001b[0m\n",
      "\u001b[34m<==== Start Training Metrics ====>\u001b[0m\n",
      "\u001b[34m{'train-mae': 5445.114716145833, 'train-rmse': 8167.234552483368, 'valid-mae': 7012.789830846472, 'valid-rmse': 10061.348515050917, 'time_this_iter_s': 0.019658803939819336, 'should_checkpoint': True, 'done': True, 'training_iteration': 101, 'trial_id': 'a9381_00000', 'date': '2023-07-04_20-45-14', 'timestamp': 1688503514, 'time_total_s': 5.372997283935547, 'pid': 803, 'hostname': 'ip-10-0-89-86.ec2.internal', 'node_ip': '10.0.89.86', 'config': {}, 'time_since_restore': 5.372997283935547, 'iterations_since_restore': 101, 'experiment_tag': '0'}\u001b[0m\n",
      "\u001b[34m<==== END Training Metrics ====>\u001b[0m\n",
      "\u001b[34m[1] #011train-mae:5445.114716145833\u001b[0m\n",
      "\u001b[34m[2] #011train-rmse:8167.234552483368\u001b[0m\n",
      "\u001b[34m[3] #011validation-mae:7012.789830846472\u001b[0m\n",
      "\u001b[34m[4] #011validation-rmse:10061.348515050917\u001b[0m\n",
      "\u001b[34mTOTAL TIME TAKEN: 11.88 seconds\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m   num_files = len(self._pq_ds.pieces)\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m   self._pq_ds.pieces[idx]\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_get_read_tasks pid=583)#033[0m   np.array_split(self._pq_ds.pieces, parallelism),\u001b[0m\n",
      "\u001b[34m#033[2m#033[36m(_RemoteRayXGBoostActor pid=1162)#033[0m [20:45:11] task [xgboost.ray]:140636035970240 got new rank 2#033[32m [repeated 2x across cluster]#033[0m\u001b[0m\n",
      "Training seconds: 346\n",
      "Billable seconds: 346\n"
     ]
    }
   ],
   "source": [
    "from helper_library import *\n",
    "# Register model\n",
    "best_estimator = tuner.best_estimator()\n",
    "model_metrics = create_training_job_metrics(best_estimator, s3_prefix, region, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493f51a7-9185-4a7a-a8fa-284626d6fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package = best_estimator.register(content_types=['text/csv'],\n",
    "                                        response_types=['application/json'],\n",
    "                                        inference_instances=['ml.t2.medium', 'ml.m5.xlarge'],\n",
    "                                        transform_instances=['ml.m5.xlarge'],\n",
    "                                        image_uri=best_estimator.image_uri,\n",
    "                                        model_package_group_name=model_package_group_name,\n",
    "                                        model_metrics=model_metrics,\n",
    "                                        approval_status='PendingManualApproval',\n",
    "                                        description='XGBoost model to predict synthetic housing prices',\n",
    "                                        model_name=model_name,\n",
    "                                        name=model_name)\n",
    "model_package_arn = model_package.model_package_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab31bb3-ed22-4f5b-b51a-4070d4980ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_package_arn' (str)\n",
      "Stored 'model_name' (str)\n",
      "Stored 'model_package_group_name' (str)\n",
      "Stored 'model_metrics' (ModelMetrics)\n"
     ]
    }
   ],
   "source": [
    "%store model_package_arn\n",
    "%store model_name\n",
    "%store model_package_group_name\n",
    "%store model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2815de-5d7d-4fa3-97e7-2f1b5b3d3c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
