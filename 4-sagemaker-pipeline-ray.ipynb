{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b70349-6d60-439b-96f9-6d51ad738101",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a66ee-baca-4d20-b713-5950c7e18248",
   "metadata": {},
   "source": [
    "This is our fourth notebook (Lab 2) which will dive deep into automating machine learning workflows to create a more repeatable path to production.  \n",
    "\n",
    "Here, we will put on the hat of a `ML Engineer` and perform the tasks required to automate the tasks within our machine learning workflows as well as orchestrate the steps.  For this, we'll build pipeline steps that include all the previous notebooks components into one singular entity. This pipeline entity accomplishes a repeatable ML workflow with some reliability built in through quality minimal quality gates. \n",
    "\n",
    "For this task we will be using Amazon SageMaker Pipelines capabilities to build out an end-to-end machine learning pipeline.   \n",
    "\n",
    "![Notebook4](images/Notebook-4.png)\n",
    "\n",
    "Keep in mind, CI/CD practicies are typically more aligned with the *Reliable* stage so you'll notice we have not yet considered a more robust set of pipelines that considers the lifecycle of each stage (build vs deploy), source/version control, automated triggers, or additional quality gates. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7fd54d-9a9a-469c-9682-47aebd040627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.171.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.153)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.153 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.153)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (67.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.153->boto3<2.0,>=1.26.131->sagemaker) (1.26.16)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bddc040-672a-4f39-b587-5ac5059e690c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c5d65d2-2733-4e6c-b858-ad25ae277706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing imports\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "# SageMaker Pipeline imports\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "# Other imports\n",
    "import json\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.tuner import IntegerParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "# To test the endpoint once it's deployed\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer, CSVDeserializer\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "import pandas as pd\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from helper_library import *\n",
    "\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bebc0d-cffb-4969-a44e-1cf5501603e1",
   "metadata": {},
   "source": [
    "**Session variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc34280e-cb38-4d9b-a32a-7ba90908998d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ARN from existing role: LambdaSageMakerExecutionRole\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Useful SageMaker variables\n",
    "session = PipelineSession()\n",
    "bucket = session.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = session.boto_region_name\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "aws_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "lambda_role = create_lambda_iam_role('LambdaSageMakerExecutionRole')\n",
    "# Data paths in S3\n",
    "s3_prefix = 'aws-sm-ray-workshop'\n",
    "bucket_prefix = f'{s3_prefix}/data/feature-store'\n",
    "output_path = f's3://{bucket}/{s3_prefix}/data/sm_processed'\n",
    "fs_output_path = f's3://{bucket}/{s3_prefix}/data/fs_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576aa33-7ca5-4719-9c72-a65e66da61e4",
   "metadata": {},
   "source": [
    "## Model Build pipeline with SageMaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc1681-35c5-4977-99e7-386f69f34bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Amazon SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) provides the ability to create a directed acryclic graph (DAG) containing the pipeline steps need to build and/or deploy machine learning models.  Each pipeline, created through the provided Python SDK, is a series of interconnected steps.  This same pipeline can also be exported as a JSON pipeline definition. \n",
    "\n",
    "The structure of a pipeline's DAG is determined by the data dependencies between steps. These data dependencies are created when the properties of a step's output are passed as the input to another step. The following image is a pipeline DAG that we'll be creating for our training pipeline:\n",
    "\n",
    "![](images/sagemaker-pipelines-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a62deb-04a6-4e0d-adc4-fcf3227af690",
   "metadata": {},
   "source": [
    "#### Pipeline Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb653db1-edae-4dbc-b501-45c6388382c5",
   "metadata": {},
   "source": [
    "SageMaker Pipelines supports [pipeline parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) allowing you to provide runtime parameters for each run of your pipeline.   This allows you to change key inputs for each run of your pipeline without changing your pipeline code (ex. raw data on input)\n",
    "\n",
    "Here, we'll identify the parameters and set the parameter default.  You can also use this feature to make it reusable (you'll be able to override these inputs upon executing the pipeline later in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aad95589-c285-4d96-8338-fb2ddba81ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-sm-ray-workshop/data/sm_processed'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43f661e0-2184-4032-adea-921f9636a3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(\n",
    "    name='ProcessingInstanceCount',\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "train_feature_group_name = ParameterString(\n",
    "    name='train_feature_group_name',\n",
    "    default_value='fs-train-synthetic-housing-data'\n",
    ")\n",
    "\n",
    "validation_feature_group_name = ParameterString(\n",
    "    name='validation_feature_group_name',\n",
    "    default_value='fs-val-synthetic-housing-data'\n",
    ")\n",
    "\n",
    "test_feature_group_name = ParameterString(\n",
    "    name='test_feature_group_name',\n",
    "    default_value='fs-test-synthetic-housing-data'\n",
    ")\n",
    "\n",
    "bucket_prefix = ParameterString(\n",
    "    name='bucket_prefix',\n",
    "    default_value='aws-ray-mlops-workshop/feature-store'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6fb4d-3dd5-45b4-a8aa-35cd8ed001b0",
   "metadata": {},
   "source": [
    "#### Setup Step Caching Configuration\n",
    "\n",
    "This configuration can be enabled on pipeline steps to allow SageMaker Pipelines to automatically check if a previous (successful) run of a pipeline step with the same values for specific parameters is found. If it is found, Pipelines propogates the results of that step to the next step without re-running the step saving both time and compute costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9f47071-47af-4d4b-afb3-2489b4d3d42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT12H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0df27b-cd2a-46ab-a180-535640cb629f",
   "metadata": {},
   "source": [
    "#### SageMaker Processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0802af5-b304-4bb3-9865-20d0061a7e41",
   "metadata": {},
   "source": [
    "This should look very similar to the SageMaker Processing Job you configured in notebook 2. The only new line of code is the `ProcessingStep` line at the bottom of the cell below which allows us to take the Processing Job configuration and include it as a pipeline step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b091a470-28e5-4657-99ee-f03c6d614f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_data_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='preprocess-data',\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "preprocess_dataset_step = ProcessingStep(\n",
    "    name='PreprocessData',\n",
    "    code='./pipeline_scripts/preprocessing/script.py',\n",
    "    processor=preprocess_data_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=raw_s3,\n",
    "            destination='/opt/ml/processing/input',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='train',\n",
    "            destination=f'{output_path}/train',\n",
    "            source='/opt/ml/processing/output/train'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='validation',\n",
    "            destination=f'{output_path}/validation',\n",
    "            source='/opt/ml/processing/output/validation'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='test',\n",
    "            destination=f'{output_path}/test',\n",
    "            source='/opt/ml/processing/output/test'\n",
    "        )\n",
    "    ],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da49b5bf-ec34-40db-be86-22afb1dceda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninputs={\\n        'train': ProcessingInput(\\n            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\\n                'train'\\n            ].S3Output.S3Uri,\\n            destination='/opt/ml/processing/input/train',\\n            s3_data_distribution_type='ShardedByS3Key'\\n        ),\\n        'validation': ProcessingInput(\\n            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\\n                'validation'\\n            ].S3Output.S3Uri,\\n            destination='/opt/ml/processing/input/validation',\\n            s3_data_distribution_type='ShardedByS3Key'\\n        ),\\n        'test': ProcessingInput(\\n            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\\n                'test'\\n            ].S3Output.S3Uri,\\n            \\n            destination='/opt/ml/processing/input/test',\\n            s3_data_distribution_type='ShardedByS3Key'\\n        )\\n    },\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputs={\n",
    "        'train': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/train',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        'validation': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/validation',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        'test': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            \n",
    "            destination='/opt/ml/processing/input/test',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    \n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/train/',\n",
    "            destination='/opt/ml/processing/input/train',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/validation/',\n",
    "            destination='/opt/ml/processing/input/validation',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/test/',\n",
    "            destination='/opt/ml/processing/input/test',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "35d19ba9-3b71-460b-ac77-84c24ce62cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "feature_store_ingestion = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='feature-store-ingestion',\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "processor_args = feature_store_ingestion.run(\n",
    "    code=\"./pipeline_scripts/feature-store/script.py\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    \n",
    "    inputs={\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/train'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/validation'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/test'\n",
    "        )\n",
    "    },\n",
    "    arguments=[\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--train_feature_group_name',\n",
    "                train_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--validation_feature_group_name',\n",
    "                validation_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--test_feature_group_name',\n",
    "                test_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--bucket_prefix',\n",
    "                bucket_prefix,\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    " \n",
    "feature_store_ingestion_step = ProcessingStep(\n",
    "      name='FeatureStoreIngestion'\n",
    "    , step_args=processor_args\n",
    "    , cache_config=cache_config)\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b8405-fbe7-471d-b3b1-3bc5222d1131",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SageMaker Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1125f-27c0-4e91-b140-5097871cab7e",
   "metadata": {},
   "source": [
    "This configuration should also look very similar to the SageMaker Training job you did in notebook 2. The only new line of code is the `TrainingStep` line at the bottom of the cell below to allow us to run the training job as a step in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "26ee0931-91cf-4bda-9865-3f2de1316a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.2xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "# Tuned hyperparameters\n",
    "hyperparams = {\n",
    "    \"max_depth\": \"7\",\n",
    "    \"eta\": \"0.389778\",\n",
    "    \"min_child_weight\": \"65\",\n",
    "    \"subsample\": \"0.732408\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "}\n",
    "\n",
    "train_instance_type = 'ml.c5.2xlarge'\n",
    "\n",
    "estimator_parameters = {\n",
    "    'source_dir': './pipeline_scripts/train/',\n",
    "    'entry_point': 'script-with-csv.py',\n",
    "    'framework_version': '1.7-1',\n",
    "    'instance_type': train_instance_type,\n",
    "    'instance_count': 2,\n",
    "    'hyperparameters': hyperparams,\n",
    "    'role': role_arn,\n",
    "    'base_job_name': 'XGBoost-model',\n",
    "    'output_path': f's3://{bucket}/{s3_prefix}/',\n",
    "    'image_scope': 'training'\n",
    "}\n",
    "\n",
    "estimator = XGBoost(**estimator_parameters)\n",
    "\n",
    "\"\"\"\n",
    "inputs = {\n",
    "    'train': TrainingInput(fs_train_data_loc), \n",
    "    'validation': TrainingInput(fs_val_data_loc)\n",
    "},\n",
    "\"\"\"\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='TrainModel',\n",
    "    estimator=estimator,\n",
    "   \n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n",
    "training_step.add_depends_on([preprocess_dataset_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d054495a-d0d5-4f8b-9b08-2efbd94b4da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-sm-ray-workshop/data/feature-store/train/523914011708/sagemaker/us-east-1/offline-store/fs-train--2023-07-07-13-38-54-1688737419/data'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_train_data_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb88d3-1a6a-4a93-8e83-c0c4ad169097",
   "metadata": {},
   "source": [
    "#### Model evaluation step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5126f-4886-408a-aa8c-3e984362b7d4",
   "metadata": {},
   "source": [
    "After the training step in our pipeline, we'll want to then evaluate our model's performance. To do that, we can create a SageMaker Processing Step that will utilize evaluation code (evaluation.py) that we specify to perform evaluation of the model using the test hold-out dataset that is output of the preprocess data step configured above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40b3789c-e416-407a-8d2e-893998e34979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='evaluation',\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51d44800-f9b4-4456-b82b-85e4a860e0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline_scripts/evaluate/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline_scripts/evaluate/script.py\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker', 'ray', 'modin[ray]', 'pydantic==1.10.10', 'xgboost_ray'])\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import glob\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Sagemaker specific imports\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "import modin.pandas as pd\n",
    "# Ray specific imports\n",
    "import ray\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.xgboost import XGBoostCheckpoint, XGBoostPredictor\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug('Starting evaluation.')\n",
    "    \n",
    "    model_dir = '/opt/ml/processing/model'\n",
    "    for file in os.listdir(model_dir):\n",
    "        logger.info(file)\n",
    "        \n",
    "    model_path = os.path.join(model_dir, 'model.tar.gz')\n",
    "    # Open the .tar.gz file\n",
    "    with tarfile.open(model_path, 'r:gz') as tar:\n",
    "        # Extract all files to the model directory\n",
    "        tar.extractall(path=model_dir)\n",
    "\n",
    "    for file in os.listdir(model_dir):\n",
    "        logger.debug(file)\n",
    "        \n",
    "    logger.debug('Loading model.')\n",
    "    checkpoint = XGBoostCheckpoint.from_directory(f'{model_dir}/model.xgb')\n",
    "    predictor = XGBoostPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    logger.debug('Reading test data.')\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    all_files = glob.glob(os.path.join(test_path , \"*.csv\"))\n",
    "    frames = []\n",
    "    for filename in all_files:\n",
    "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
    "        frames.append(frame)\n",
    "    df = pd.concat(frames, axis=0, ignore_index=True)\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = df.to_numpy()\n",
    "\n",
    "    \n",
    "    logger.info('Performing predictions against test data.')\n",
    "    predictions = predictor.predict(X_test)\n",
    "\n",
    "    # See the regression metrics\n",
    "    # see: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "    logger.debug('Calculating metrics.')\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        'regression_metrics': {\n",
    "            'mae': {\n",
    "                'value': mae,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'mse': {\n",
    "                'value': mse,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'rmse': {\n",
    "                'value': rmse,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'r2': {\n",
    "                'value': r2,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = '/opt/ml/processing/evaluation'\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info('Writing out evaluation report with mse: %f', mse)\n",
    "    evaluation_path = f'{output_dir}/evaluation.json'\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8dc41ce-2f02-44a1-ad06-fc0034d091aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify where we'll store the model evaluation results so\n",
    "# that other steps can access those results\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json',\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation', source='/opt/ml/processing/evaluation'\n",
    "        ),\n",
    "    ],\n",
    "    code='./pipeline_scripts/evaluate/script.py',\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "473526c9-aea1-400d-8809-dba4fac0c7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri='{}/evaluation.json'.format(\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output'][\n",
    "                'S3Uri'\n",
    "            ]\n",
    "        ),\n",
    "        content_type='application/json',\n",
    "    )\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=estimator.training_image_uri(),\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    source_dir=estimator.source_dir,\n",
    "    entry_point=estimator.entry_point,\n",
    "    role=role_arn,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "model_registry_args = model.register(\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['application/json'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status='PendingManualApproval',\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "register_step = ModelStep(\n",
    "    name='RegisterModel',\n",
    "    step_args=model_registry_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c077ce3-3d75-4fdd-a813-f3ec4e38452a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Condition step for evaluating model quality and branching execution\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path='regression_metrics.rmse.value',\n",
    "    ),\n",
    "    right=13000.0,\n",
    ")\n",
    "condition_step = ConditionStep(\n",
    "    name='CheckEvaluation',\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[register_step],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f8eb3ff7-e490-4bfa-94aa-e11f980280dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'set' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 22\u001b[0m\n\u001b[1;32m      9\u001b[0m training_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m     10\u001b[0m     name\u001b[38;5;241m=\u001b[39mpipeline_name,\n\u001b[1;32m     11\u001b[0m     parameters\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     steps\u001b[38;5;241m=\u001b[39mstep_list\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Note: If an existing pipeline has the same name it will be overwritten.\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtraining_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrole_arn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Viewing the pipeline definition will all the string variables interpolated may help debug pipeline bugs. It is commented out here due to length.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#json.loads(training_pipeline.definition())\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:290\u001b[0m, in \u001b[0;36mPipeline.upsert\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn AWS IAM role is required to create or update a Pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[1;32m    292\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:159\u001b[0m, in \u001b[0;36mPipeline.create\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    157\u001b[0m tags \u001b[38;5;241m=\u001b[39m _append_project_tags(tags)\n\u001b[1;32m    158\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39m_append_sagemaker_config_tags(tags, PIPELINE_TAGS_PATH)\n\u001b[0;32m--> 159\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m update_args(\n\u001b[1;32m    161\u001b[0m     kwargs,\n\u001b[1;32m    162\u001b[0m     Tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_pipeline(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:181\u001b[0m, in \u001b[0;36mPipeline._create_args\u001b[0;34m(self, role_arn, description, parallelism_config)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_args\u001b[39m(\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28mself\u001b[39m, role_arn: \u001b[38;5;28mstr\u001b[39m, description: \u001b[38;5;28mstr\u001b[39m, parallelism_config: ParallelismConfiguration\n\u001b[1;32m    168\u001b[0m ):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124;03m\"\"\"Constructs the keyword argument dict for a create_pipeline call.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m        A keyword argument dict for calling create_pipeline.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     pipeline_definition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    183\u001b[0m         PipelineName\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    184\u001b[0m         RoleArn\u001b[38;5;241m=\u001b[39mrole_arn,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# If pipeline definition is large, upload to S3 bucket and\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# provide PipelineDefinitionS3Location to request instead.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefinition\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124;03m\"\"\"Converts a request structure to string representation for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpolate_step_collection_name_in_depends_on(request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    380\u001b[0m     request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelineExperimentConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m interpolate(\n\u001b[1;32m    381\u001b[0m         request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelineExperimentConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m], {}, {}\n\u001b[1;32m    382\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline.py:116\u001b[0m, in \u001b[0;36mPipeline.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124;03m\"\"\"Gets the request structure for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version,\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata,\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: list_to_request(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters),\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelineExperimentConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_experiment_config\u001b[38;5;241m.\u001b[39mto_request()\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_experiment_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mbuild_steps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_definition_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    121\u001b[0m     }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/utilities.py:127\u001b[0m, in \u001b[0;36mbuild_steps\u001b[0;34m(steps, pipeline_name, pipeline_definition_config)\u001b[0m\n\u001b[1;32m    125\u001b[0m             request_dicts\u001b[38;5;241m.\u001b[39mextend(step\u001b[38;5;241m.\u001b[39mrequest_dicts())\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m             request_dicts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m request_dicts\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/steps.py:917\u001b[0m, in \u001b[0;36mProcessingStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the request structure for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mProcessingStep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config:\n\u001b[1;32m    919\u001b[0m         request_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/steps.py:353\u001b[0m, in \u001b[0;36mConfigurableRetryStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124;03m\"\"\"Gets the request structure for `ConfigurableRetryStep`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     step_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policies:\n\u001b[1;32m    355\u001b[0m         step_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryPolicies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_retry_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policies)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/steps.py:122\u001b[0m, in \u001b[0;36mStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124;03m\"\"\"Gets the request structure for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_type\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m,\n\u001b[1;32m    123\u001b[0m     }\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on:\n\u001b[1;32m    125\u001b[0m         request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependsOn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_depends_on(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/steps.py:884\u001b[0m, in \u001b[0;36mProcessingStep.arguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pipeline_config\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_args:\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;66;03m# execute run function with saved parameters,\u001b[39;00m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;66;03m# and store args in PipelineSession's _context\u001b[39;00m\n\u001b[0;32m--> 884\u001b[0m     \u001b[43mexecute_job_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# populate request dict with args\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_args\u001b[38;5;241m.\u001b[39mfunc_args[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/utilities.py:435\u001b[0m, in \u001b[0;36mexecute_job_functions\u001b[0;34m(step_args)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_job_functions\u001b[39m(step_args: _StepArguments):\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124;03m\"\"\"Execute the job class functions during pipeline definition construction\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    Executes the job functions such as run(), fit(), or transform() that have been\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m            a pipeline step, contains the necessary function information\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     chained_args \u001b[38;5;241m=\u001b[39m \u001b[43mstep_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chained_args, _StepArguments):\n\u001b[1;32m    437\u001b[0m         execute_job_functions(chained_args)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:670\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;129m@runnable_by_pipeline\u001b[39m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     kms_key: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m ):\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;124;03m\"\"\"Runs a processing job.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m        :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m     normalized_inputs, normalized_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    679\u001b[0m     experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job \u001b[38;5;241m=\u001b[39m ProcessingJob\u001b[38;5;241m.\u001b[39mstart_new(\n\u001b[1;32m    681\u001b[0m         processor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    682\u001b[0m         inputs\u001b[38;5;241m=\u001b[39mnormalized_inputs,\n\u001b[1;32m    683\u001b[0m         outputs\u001b[38;5;241m=\u001b[39mnormalized_outputs,\n\u001b[1;32m    684\u001b[0m         experiment_config\u001b[38;5;241m=\u001b[39mexperiment_config,\n\u001b[1;32m    685\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:318\u001b[0m, in \u001b[0;36mProcessor._normalize_args\u001b[0;34m(self, job_name, arguments, inputs, outputs, code, kms_key)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode argument has to be a valid S3 URI or local file path \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrather than a pipeline variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_current_job_name(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[0;32m--> 318\u001b[0m inputs_with_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_include_code_in_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m normalized_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_inputs(inputs_with_code, kms_key)\n\u001b[1;32m    320\u001b[0m normalized_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_outputs(outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:713\u001b[0m, in \u001b[0;36mScriptProcessor._include_code_in_inputs\u001b[0;34m(self, inputs, code, kms_key)\u001b[0m\n\u001b[1;32m    710\u001b[0m user_code_s3_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_user_code_url(code, kms_key)\n\u001b[1;32m    711\u001b[0m user_script_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_user_code_name(code)\n\u001b[0;32m--> 713\u001b[0m inputs_with_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_code_and_add_to_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_code_s3_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_entrypoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand, user_script_name)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs_with_code\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:840\u001b[0m, in \u001b[0;36mScriptProcessor._convert_code_and_add_to_inputs\u001b[0;34m(self, inputs, s3_uri)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a ``ProcessingInput`` object from an S3 URI and adds it to the list of inputs.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \n\u001b[1;32m    820\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m \n\u001b[1;32m    829\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    831\u001b[0m code_file_input \u001b[38;5;241m=\u001b[39m ProcessingInput(\n\u001b[1;32m    832\u001b[0m     source\u001b[38;5;241m=\u001b[39ms3_uri,\n\u001b[1;32m    833\u001b[0m     destination\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CODE_CONTAINER_INPUT_NAME,\n\u001b[1;32m    839\u001b[0m )\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcode_file_input\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'set' and 'list'"
     ]
    }
   ],
   "source": [
    "# pipeline_name = 'synthetic-housing-training-pipeline-{}'.format(strftime('%d-%H-%M-%S', gmtime()))\n",
    "pipeline_name = 'synthetic-housing-training-pipeline-ray'\n",
    "step_list = [preprocess_dataset_step,\n",
    "             feature_store_ingestion_step,\n",
    "             training_step,\n",
    "             evaluation_step,\n",
    "             condition_step]\n",
    "\n",
    "training_pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        train_feature_group_name,\n",
    "        validation_feature_group_name,\n",
    "        test_feature_group_name,\n",
    "        bucket_prefix\n",
    "    ],\n",
    "    steps=step_list\n",
    ")\n",
    "\n",
    "# Note: If an existing pipeline has the same name it will be overwritten.\n",
    "training_pipeline.upsert(role_arn=role_arn)\n",
    "\n",
    "# Viewing the pipeline definition will all the string variables interpolated may help debug pipeline bugs. It is commented out here due to length.\n",
    "#json.loads(training_pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233da42-702b-421f-a234-881cee1a2495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(feature_store_ingestion_step.inputs['validation'].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61e7059e-74fa-42dc-be57-bdb79c5f3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you could optionally override parameter defaults \n",
    "execution = training_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9381d7d5-d9b1-4603-aa63-b80a56904201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871be26b-b530-4316-b5ce-6d5bb23b3b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker', 'ray', 'modin[ray]', 'pydantic==1.10.10'])\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Sagemaker specific imports\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "import modin.pandas as pd\n",
    "# Ray specific imports\n",
    "import ray\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data import Dataset\n",
    "from ray.air.result import Result\n",
    "from ray.air.checkpoint import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ff63d-587b-4dda-ab3d-d2aceb4a8fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs_test_data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f6163-5ff3-438c-b099-a7bc75bb00b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Starting evaluation.')\n",
    "#ray.init()  \n",
    "#model_dir = '/opt/ml/processing/model'\n",
    "model_dir = './common/'\n",
    "model_path = os.path.join(model_dir, 'model.tar.gz')\n",
    "print(model_path)\n",
    "\n",
    "# Open the .tar.gz file\n",
    "with tarfile.open(model_path, 'r:gz') as tar:\n",
    "    # Extract all files\n",
    "    tar.extractall(path=model_dir)\n",
    "\n",
    "# Optional: Print the list of extracted files\n",
    "with tarfile.open(model_path, 'r:gz') as tar:\n",
    "    file_names = tar.getnames()\n",
    "    print(\"Extracted files:\")\n",
    "    for name in file_names:\n",
    "        print(name)\n",
    "\n",
    "checkpoint = ray.train.xgboost.XGBoostCheckpoint.from_directory(f'{model_dir}model.xgb/')\n",
    "predictor = ray.train.xgboost.XGBoostPredictor.from_checkpoint(checkpoint)\n",
    "print(dir(predictor))\n",
    "\n",
    "\n",
    "#test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "test_path = fs_test_data_loc\n",
    "\n",
    "all_files = glob.glob(os.path.join(fs_test_data_loc , \"/*.csv\"))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# df = pd.read_csv(test_path, header=0)\n",
    "df.head(5)\n",
    "y_test = df.iloc[:, 0].to_numpy()\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "X_test = df.to_numpy()\n",
    "predictions = predictor.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac8c32-09d1-4612-afea-1491b4a10784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b99c8f-ec80-4ca4-b7dc-18bc54b55da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423378c-213a-4438-9146-8889c82203fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See the regression metrics\n",
    "# see: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "std = np.std(y_test - predictions)\n",
    "report_dict = {\n",
    "    'regression_metrics': {\n",
    "        'mae': {\n",
    "            'value': mae,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'mse': {\n",
    "            'value': mse,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'rmse': {\n",
    "            'value': rmse,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'r2': {\n",
    "            'value': r2,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "output_dir = '/opt/ml/processing/evaluation'\n",
    "pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "evaluation_path = f'{model_dir}/evaluation.json'\n",
    "with open(evaluation_path, 'w') as f:\n",
    "    f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c329973-413b-4a9f-9d40-891a3e1af9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad054e-3eec-4e8a-84a6-486fb95bea56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./pipeline_scripts/evaluate/script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70722d25-a54d-4908-a742-40fd644bf633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to download the model from Sagemaker Model registry\n",
    "def download_model(model_name, download_path):\n",
    "    # Create a Boto3 SageMaker client\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "\n",
    "    # Get the details of the model package\n",
    "    response = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=model_name\n",
    "    )\n",
    "\n",
    "    # Retrieve the S3 location of the model package\n",
    "    model_package_location = response['InferenceSpecification']['Containers'][0]['ModelDataUrl']\n",
    "    print(model_package_location)\n",
    "    # Download the model package\n",
    "    s3_client = boto3.client('s3')\n",
    "    #bucket_name = 'your-bucket-name'  # Replace with your S3 bucket name\n",
    "    download_path = './common/model.tar.gz'  # Specify the local download path\n",
    "\n",
    "    s3_client.download_file(bucket, model_package_location, download_path)\n",
    "\n",
    "    print(\"Model downloaded successfully.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710f145-a271-47e8-813f-a719f5190ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_model(model_package_arn, './common/')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4bc72e2-adf8-4d2f-a9ae-265b102a262a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call show on the output probabilities to trigger execution.\n",
    "predicted_probabilities.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba828c-a98e-4fe3-a782-e8e918e8df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af61903-2bf9-4409-b350-747415148ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89594588-22f2-4d16-b405-3215d28747a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
