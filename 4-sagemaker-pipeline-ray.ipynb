{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b70349-6d60-439b-96f9-6d51ad738101",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a66ee-baca-4d20-b713-5950c7e18248",
   "metadata": {},
   "source": [
    "This is our fourth notebook (Lab 2) which will dive deep into automating machine learning workflows to create a more repeatable path to production.  \n",
    "\n",
    "Here, we will put on the hat of a `ML Engineer` and perform the tasks required to automate the tasks within our machine learning workflows as well as orchestrate the steps.  For this, we'll build pipeline steps that include all the previous notebooks components into one singular entity. This pipeline entity accomplishes a repeatable ML workflow with some reliability built in through quality minimal quality gates. \n",
    "\n",
    "For this task we will be using Amazon SageMaker Pipelines capabilities to build out an end-to-end machine learning pipeline.   \n",
    "\n",
    "![Notebook4](images/Notebook-4.png)\n",
    "\n",
    "Keep in mind, CI/CD practicies are typically more aligned with the *Reliable* stage so you'll notice we have not yet considered a more robust set of pipelines that considers the lifecycle of each stage (build vs deploy), source/version control, automated triggers, or additional quality gates. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e7fd54d-9a9a-469c-9682-47aebd040627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.171.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.153)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.5.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.153 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.153)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (67.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2022.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.153->boto3<2.0,>=1.26.131->sagemaker) (1.26.16)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bddc040-672a-4f39-b587-5ac5059e690c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c5d65d2-2733-4e6c-b858-ad25ae277706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing imports\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "\n",
    "# SageMaker Pipeline imports\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep, TransformStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "# Other imports\n",
    "import json\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.tuner import IntegerParameter, HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "# To test the endpoint once it's deployed\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer, CSVDeserializer\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "from sagemaker.model_metrics import ModelMetrics, MetricsSource\n",
    "import pandas as pd\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from helper_library import *\n",
    "\n",
    "from sagemaker.workflow.steps import CacheConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bebc0d-cffb-4969-a44e-1cf5501603e1",
   "metadata": {},
   "source": [
    "**Session variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc34280e-cb38-4d9b-a32a-7ba90908998d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ARN from existing role: LambdaSageMakerExecutionRole\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Useful SageMaker variables\n",
    "session = PipelineSession()\n",
    "bucket = session.default_bucket()\n",
    "role_arn= sagemaker.get_execution_role()\n",
    "region = session.boto_region_name\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "aws_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "lambda_role = create_lambda_iam_role('LambdaSageMakerExecutionRole')\n",
    "# Data paths in S3\n",
    "s3_prefix = 'aws-sm-ray-workshop'\n",
    "bucket_prefix = f'{s3_prefix}/data/feature-store'\n",
    "output_path = f's3://{bucket}/{s3_prefix}/data/sm_processed'\n",
    "fs_s3_path = f's3://{bucket}/{s3_prefix}/data/feature-store'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576aa33-7ca5-4719-9c72-a65e66da61e4",
   "metadata": {},
   "source": [
    "## Model Build pipeline with SageMaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc1681-35c5-4977-99e7-386f69f34bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Amazon SageMaker Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html) provides the ability to create a directed acryclic graph (DAG) containing the pipeline steps need to build and/or deploy machine learning models.  Each pipeline, created through the provided Python SDK, is a series of interconnected steps.  This same pipeline can also be exported as a JSON pipeline definition. \n",
    "\n",
    "The structure of a pipeline's DAG is determined by the data dependencies between steps. These data dependencies are created when the properties of a step's output are passed as the input to another step. The following image is a pipeline DAG that we'll be creating for our training pipeline:\n",
    "\n",
    "![](images/sagemaker-pipelines-dag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a62deb-04a6-4e0d-adc4-fcf3227af690",
   "metadata": {},
   "source": [
    "#### Pipeline Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb653db1-edae-4dbc-b501-45c6388382c5",
   "metadata": {},
   "source": [
    "SageMaker Pipelines supports [pipeline parameters](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html) allowing you to provide runtime parameters for each run of your pipeline.   This allows you to change key inputs for each run of your pipeline without changing your pipeline code (ex. raw data on input)\n",
    "\n",
    "Here, we'll identify the parameters and set the parameter default.  You can also use this feature to make it reusable (you'll be able to override these inputs upon executing the pipeline later in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aad95589-c285-4d96-8338-fb2ddba81ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload raw data to S3\n",
    "local_data_path_ray = \"data/raw/ray/house_pricing.csv\"\n",
    "raw_data_s3_prefix = '{}/data/raw'.format(s3_prefix)\n",
    "raw_s3 = session.upload_data(path=local_data_path_ray, key_prefix=raw_data_s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43f661e0-2184-4032-adea-921f9636a3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_instance_count = ParameterInteger(\n",
    "    name='ProcessingInstanceCount',\n",
    "    default_value=1\n",
    ")\n",
    "\"\"\"\n",
    "train_feature_group_name = ParameterString(\n",
    "    name='train_feature_group_name',\n",
    "    default_value='fs-train-synthetic-housing-data'\n",
    ")\n",
    "\n",
    "validation_feature_group_name = ParameterString(\n",
    "    name='validation_feature_group_name',\n",
    "    default_value='fs-val-synthetic-housing-data'\n",
    ")\n",
    "\n",
    "test_feature_group_name = ParameterString(\n",
    "    name='test_feature_group_name',\n",
    "    default_value='fs-test-synthetic-housing-data'\n",
    ")\n",
    "\"\"\"\n",
    "bucket_prefix = ParameterString(\n",
    "    name='bucket_prefix',\n",
    "    default_value='aws-ray-mlops-workshop/feature-store'\n",
    ")\n",
    "\n",
    "train_feature_group_name = 'fs-train-synthetic-housing-data'\n",
    "validation_feature_group_name = 'fs-val-synthetic-housing-data'\n",
    "test_feature_group_name = 'fs-test-synthetic-housing-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6fb4d-3dd5-45b4-a8aa-35cd8ed001b0",
   "metadata": {},
   "source": [
    "#### Setup Step Caching Configuration\n",
    "\n",
    "This configuration can be enabled on pipeline steps to allow SageMaker Pipelines to automatically check if a previous (successful) run of a pipeline step with the same values for specific parameters is found. If it is found, Pipelines propogates the results of that step to the next step without re-running the step saving both time and compute costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9f47071-47af-4d4b-afb3-2489b4d3d42b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT12H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0df27b-cd2a-46ab-a180-535640cb629f",
   "metadata": {},
   "source": [
    "#### SageMaker Processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0802af5-b304-4bb3-9865-20d0061a7e41",
   "metadata": {},
   "source": [
    "This should look very similar to the SageMaker Processing Job you configured in notebook 2. The only new line of code is the `ProcessingStep` line at the bottom of the cell below which allows us to take the Processing Job configuration and include it as a pipeline step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b091a470-28e5-4657-99ee-f03c6d614f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "preprocess_data_processor = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='preprocess-data',\n",
    "    sagemaker_session=session,\n",
    "    \n",
    ")\n",
    "\n",
    "preprocess_dataset_step = ProcessingStep(\n",
    "    name='PreprocessData',\n",
    "    code='./pipeline_scripts/preprocessing/script.py',\n",
    "    processor=preprocess_data_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=raw_s3,\n",
    "            destination='/opt/ml/processing/input',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='train',\n",
    "            destination=f'{output_path}/train',\n",
    "            source='/opt/ml/processing/output/train'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='validation',\n",
    "            destination=f'{output_path}/validation',\n",
    "            source='/opt/ml/processing/output/validation'\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name='test',\n",
    "            destination=f'{output_path}/test',\n",
    "            source='/opt/ml/processing/output/test'\n",
    "        )\n",
    "    ],\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da49b5bf-ec34-40db-be86-22afb1dceda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n        ProcessingOutput(output_name=\"validation\", source=f\"fs_s3_path/validation/{aws_account_id}/sagemaker/{region}/offline-store/{validation_feature_group_name}/data\"),\\n        ProcessingOutput(output_name=\"test\", source=f\"fs_s3_path/test/{aws_account_id}/sagemaker/{region}/offline-store/{test_feature_group_name}/data\")\\n        \\n        \\n            outputs=[\\n        ProcessingOutput(output_name=\"train\", source=Join(on=\\'/\\', values=[fs_s3_path,\\'train\\', aws_account_id, \\'sagemaker\\', region, \\'offline-store\\', train_feature_group_name, \\'data\\'])),\\n        ProcessingOutput(output_name=\"validation\", source=Join(on=\\'/\\', values=[fs_s3_path, \\'validation\\', aws_account_id, \\'sagemaker\\', region, \\'offline-store\\', validation_feature_group_name, \\'data\\'])),\\n        ProcessingOutput(output_name=\"test\", source=Join(on=\\'/\\', values=[fs_s3_path, \\'test\\', aws_account_id, \\'sagemaker\\', region, \\'offline-store\\', test_feature_group_name, \\'data\\'])),      \\n    ],\\n    \\n    \\n    \\n    arguments=[\\n        Join(\\n            on=\\' \\',\\n            values=[\\n                \\'--train_feature_group_name\\',\\n                train_feature_group_name,\\n            ],\\n        ),\\n        Join(\\n            on=\\' \\',\\n            values=[\\n                \\'--validation_feature_group_name\\',\\n                validation_feature_group_name,\\n            ],\\n        ),\\n        Join(\\n            on=\\' \\',\\n            values=[\\n                \\'--test_feature_group_name\\',\\n                test_feature_group_name,\\n            ],\\n        ),\\n        Join(\\n            on=\\' \\',\\n            values=[\\n                \\'--bucket_prefix\\',\\n                bucket_prefix,\\n            ],\\n        ),\\n        Join(\\n            on=\\' \\',\\n            values=[\\n                \\'--region\\',\\n                region,\\n            ],\\n        ),\\n    ]\\n    \\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputs={\n",
    "        'train': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/train',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        'validation': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/validation',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        'test': ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            \n",
    "            destination='/opt/ml/processing/input/test',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    },\n",
    "    \n",
    "    \n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/train/',\n",
    "            destination='/opt/ml/processing/input/train',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/validation/',\n",
    "            destination='/opt/ml/processing/input/validation',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=f'{output_path}/test/',\n",
    "            destination='/opt/ml/processing/input/test',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "    ],\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        ProcessingOutput(output_name=\"validation\", source=f\"fs_s3_path/validation/{aws_account_id}/sagemaker/{region}/offline-store/{validation_feature_group_name}/data\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=f\"fs_s3_path/test/{aws_account_id}/sagemaker/{region}/offline-store/{test_feature_group_name}/data\")\n",
    "        \n",
    "        \n",
    "            outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=Join(on='/', values=[fs_s3_path,'train', aws_account_id, 'sagemaker', region, 'offline-store', train_feature_group_name, 'data'])),\n",
    "        ProcessingOutput(output_name=\"validation\", source=Join(on='/', values=[fs_s3_path, 'validation', aws_account_id, 'sagemaker', region, 'offline-store', validation_feature_group_name, 'data'])),\n",
    "        ProcessingOutput(output_name=\"test\", source=Join(on='/', values=[fs_s3_path, 'test', aws_account_id, 'sagemaker', region, 'offline-store', test_feature_group_name, 'data'])),      \n",
    "    ],\n",
    "    \n",
    "    \n",
    "    \n",
    "    arguments=[\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--train_feature_group_name',\n",
    "                train_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--validation_feature_group_name',\n",
    "                validation_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--test_feature_group_name',\n",
    "                test_feature_group_name,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--bucket_prefix',\n",
    "                bucket_prefix,\n",
    "            ],\n",
    "        ),\n",
    "        Join(\n",
    "            on=' ',\n",
    "            values=[\n",
    "                '--region',\n",
    "                region,\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35d19ba9-3b71-460b-ac77-84c24ce62cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "feature_store_ingestion = SKLearnProcessor(\n",
    "    framework_version='1.0-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='feature-store-ingestion',\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "processor_args = feature_store_ingestion.run(\n",
    "    code=\"./pipeline_scripts/feature-store/script.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'train'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/train'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'validation'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/validation'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'test'\n",
    "            ].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/test'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", s3_upload_mode='Continuous', app_managed=True, feature_store_output = sagemaker.processing.FeatureStoreOutput(feature_group_name = train_feature_group_name)),\n",
    "        ProcessingOutput(output_name=\"validation\", s3_upload_mode='Continuous', app_managed=True, feature_store_output = sagemaker.processing.FeatureStoreOutput(feature_group_name = validation_feature_group_name)),\n",
    "    ],  \n",
    "    arguments=['--train_feature_group_name', train_feature_group_name,\n",
    "                '--validation_feature_group_name', validation_feature_group_name,\n",
    "                '--test_feature_group_name', test_feature_group_name,\n",
    "                '--bucket_prefix', bucket_prefix,\n",
    "                '--role_arn', role_arn,\n",
    "                '--region', region,\n",
    "    ]\n",
    ")\n",
    " \n",
    "feature_store_ingestion_step = ProcessingStep(\n",
    "    name='FeatureStoreIngestion',\n",
    "    step_args=processor_args,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b8405-fbe7-471d-b3b1-3bc5222d1131",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SageMaker Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1125f-27c0-4e91-b140-5097871cab7e",
   "metadata": {},
   "source": [
    "This configuration should also look very similar to the SageMaker Training job you did in notebook 2. The only new line of code is the `TrainingStep` line at the bottom of the cell below to allow us to run the training job as a step in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ab781c2-62ea-404c-8e84-e13d7b7ac483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        inputs={\\n        \\'train\\': TrainingInput(feature_store_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"train\"].FeatureStoreOutput.FeatureGroupName),\\n        \\'validation\\': TrainingInput(feature_store_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].FeatureStoreOutput.FeatureGroupName)\\n    },\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "        inputs={\n",
    "        'train': TrainingInput(feature_store_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"train\"].FeatureStoreOutput.FeatureGroupName),\n",
    "        'validation': TrainingInput(feature_store_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].FeatureStoreOutput.FeatureGroupName)\n",
    "    },\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26ee0931-91cf-4bda-9865-3f2de1316a95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.c5.2xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    # Tuned hyperparameters\n",
    "    \"max_depth\": \"7\",\n",
    "    \"eta\": \"0.389778\",\n",
    "    \"min_child_weight\": \"65\",\n",
    "    \"subsample\": \"0.732408\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    # Training job params\n",
    "    \"train_feature_group_name\": train_feature_group_name,\n",
    "    \"validation_feature_group_name\": validation_feature_group_name,\n",
    "    \"role_arn\": role_arn,\n",
    "    \"region\": region,\n",
    "}\n",
    "\n",
    "train_instance_type = 'ml.c5.2xlarge'\n",
    "\n",
    "estimator_parameters = {\n",
    "    'source_dir': './pipeline_scripts/train/',\n",
    "    'entry_point': 'script-pipeline.py',\n",
    "    'framework_version': '1.7-1',\n",
    "    'instance_type': train_instance_type,\n",
    "    'instance_count': 2,\n",
    "    'hyperparameters': hyperparams,\n",
    "    'role': role_arn,\n",
    "    'base_job_name': 'XGBoost-model',\n",
    "    'output_path': f's3://{bucket}/{s3_prefix}/',\n",
    "    'image_scope': 'training'\n",
    "}\n",
    "\n",
    "estimator = XGBoost(**estimator_parameters)\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='TrainModel',\n",
    "    estimator=estimator,\n",
    "    cache_config=cache_config\n",
    ")\n",
    "training_step.add_depends_on([feature_store_ingestion_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb88d3-1a6a-4a93-8e83-c0c4ad169097",
   "metadata": {},
   "source": [
    "#### Model evaluation step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5126f-4886-408a-aa8c-3e984362b7d4",
   "metadata": {},
   "source": [
    "After the training step in our pipeline, we'll want to then evaluate our model's performance. To do that, we can create a SageMaker Processing Step that will utilize evaluation code (evaluation.py) that we specify to perform evaluation of the model using the test hold-out dataset that is output of the preprocess data step configured above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f39c3de4-8896-4071-8b9d-c8f76103be56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FeatureGroupName',\n",
       " '__abstractmethods__',\n",
       " '__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_referenced_steps',\n",
       " '_shape_names',\n",
       " 'expr',\n",
       " 'path',\n",
       " 'step_name',\n",
       " 'to_string']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(feature_store_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"train\"].FeatureStoreOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40b3789c-e416-407a-8d2e-893998e34979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role_arn,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name='evaluation',\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51d44800-f9b4-4456-b82b-85e4a860e0e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline_scripts/evaluate/script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline_scripts/evaluate/script.py\n",
    "import subprocess\n",
    "import sys\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker', 'ray', 'modin[ray]', 'pydantic==1.10.10', 'xgboost_ray'])\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import glob\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Sagemaker specific imports\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "import modin.pandas as pd\n",
    "# Ray specific imports\n",
    "import ray\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.train.xgboost import XGBoostCheckpoint, XGBoostPredictor\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug('Starting evaluation.')\n",
    "    \n",
    "    model_dir = '/opt/ml/processing/model'\n",
    "    for file in os.listdir(model_dir):\n",
    "        logger.info(file)\n",
    "        \n",
    "    model_path = os.path.join(model_dir, 'model.tar.gz')\n",
    "    # Open the .tar.gz file\n",
    "    with tarfile.open(model_path, 'r:gz') as tar:\n",
    "        # Extract all files to the model directory\n",
    "        tar.extractall(path=model_dir)\n",
    "\n",
    "    for file in os.listdir(model_dir):\n",
    "        logger.debug(file)\n",
    "        \n",
    "    logger.debug('Loading model.')\n",
    "    checkpoint = XGBoostCheckpoint.from_directory(f'{model_dir}/model.xgb')\n",
    "    predictor = XGBoostPredictor.from_checkpoint(checkpoint)\n",
    "\n",
    "    logger.debug('Reading test data.')\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    all_files = glob.glob(os.path.join(test_path , \"*.csv\"))\n",
    "    frames = []\n",
    "    for filename in all_files:\n",
    "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
    "        frames.append(frame)\n",
    "    df = pd.concat(frames, axis=0, ignore_index=True)\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = df.to_numpy()\n",
    "\n",
    "    \n",
    "    logger.info('Performing predictions against test data.')\n",
    "    predictions = predictor.predict(X_test)\n",
    "\n",
    "    # See the regression metrics\n",
    "    # see: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "    logger.debug('Calculating metrics.')\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        'regression_metrics': {\n",
    "            'mae': {\n",
    "                'value': mae,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'mse': {\n",
    "                'value': mse,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'rmse': {\n",
    "                'value': rmse,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "            'r2': {\n",
    "                'value': r2,\n",
    "                'standard_deviation': std,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = '/opt/ml/processing/evaluation'\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info('Writing out evaluation report with mse: %f', mse)\n",
    "    evaluation_path = f'{output_dir}/evaluation.json'\n",
    "    with open(evaluation_path, 'w') as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8dc41ce-2f02-44a1-ad06-fc0034d091aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify where we'll store the model evaluation results so\n",
    "# that other steps can access those results\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='evaluation',\n",
    "    path='evaluation.json',\n",
    ")\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    processor=evaluation_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/model',\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=preprocess_dataset_step.properties.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/test',\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name='evaluation', source='/opt/ml/processing/evaluation'\n",
    "        ),\n",
    "    ],\n",
    "    code='./pipeline_scripts/evaluate/script.py',\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "473526c9-aea1-400d-8809-dba4fac0c7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri='{}/evaluation.json'.format(\n",
    "            evaluation_step.arguments['ProcessingOutputConfig']['Outputs'][0]['S3Output'][\n",
    "                'S3Uri'\n",
    "            ]\n",
    "        ),\n",
    "        content_type='application/json',\n",
    "    )\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    image_uri=estimator.training_image_uri(),\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    source_dir=estimator.source_dir,\n",
    "    entry_point=estimator.entry_point,\n",
    "    role=role_arn,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "model_registry_args = model.register(\n",
    "    content_types=['text/csv'],\n",
    "    response_types=['application/json'],\n",
    "    inference_instances=['ml.t2.medium', 'ml.m5.xlarge'],\n",
    "    transform_instances=['ml.m5.xlarge'],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status='PendingManualApproval',\n",
    "    model_metrics=model_metrics\n",
    ")\n",
    "\n",
    "register_step = ModelStep(\n",
    "    name='RegisterModel',\n",
    "    step_args=model_registry_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c077ce3-3d75-4fdd-a813-f3ec4e38452a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Condition step for evaluating model quality and branching execution\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluation_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path='regression_metrics.rmse.value',\n",
    "    ),\n",
    "    right=13000.0,\n",
    ")\n",
    "condition_step = ConditionStep(\n",
    "    name='CheckEvaluation',\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[register_step],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8eb3ff7-e490-4bfa-94aa-e11f980280dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:523914011708:pipeline/synthetic-housing-training-pipeline-ray',\n",
       " 'ResponseMetadata': {'RequestId': 'f00b3d08-2db6-4a0c-b3dc-36990465e166',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f00b3d08-2db6-4a0c-b3dc-36990465e166',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '107',\n",
       "   'date': 'Sun, 09 Jul 2023 04:11:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline_name = 'synthetic-housing-training-pipeline-{}'.format(strftime('%d-%H-%M-%S', gmtime()))\n",
    "pipeline_name = 'synthetic-housing-training-pipeline-ray'\n",
    "step_list = [preprocess_dataset_step,\n",
    "             feature_store_ingestion_step,\n",
    "             training_step,\n",
    "             evaluation_step,\n",
    "             condition_step]\n",
    "\n",
    "training_pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        train_feature_group_name,\n",
    "        validation_feature_group_name,\n",
    "        test_feature_group_name,\n",
    "        bucket_prefix\n",
    "    ],\n",
    "    steps=step_list\n",
    ")\n",
    "\n",
    "# Note: If an existing pipeline has the same name it will be overwritten.\n",
    "training_pipeline.upsert(role_arn=role_arn)\n",
    "\n",
    "# Viewing the pipeline definition will all the string variables interpolated may help debug pipeline bugs. It is commented out here due to length.\n",
    "#json.loads(training_pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61e7059e-74fa-42dc-be57-bdb79c5f3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you could optionally override parameter defaults \n",
    "execution = training_pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9381d7d5-d9b1-4603-aa63-b80a56904201",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:523914011708:pipeline/synthetic-housing-training-pipeline-ray',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:523914011708:pipeline/synthetic-housing-training-pipeline-ray/execution/29twllgnctji',\n",
       " 'PipelineExecutionDisplayName': 'execution-1688875913757',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2023, 7, 9, 4, 11, 53, 690000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2023, 7, 9, 4, 11, 53, 690000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:523914011708:user-profile/d-zbtbfrmc31iz/user-1',\n",
       "  'UserProfileName': 'user-1',\n",
       "  'DomainId': 'd-zbtbfrmc31iz'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:523914011708:user-profile/d-zbtbfrmc31iz/user-1',\n",
       "  'UserProfileName': 'user-1',\n",
       "  'DomainId': 'd-zbtbfrmc31iz'},\n",
       " 'ResponseMetadata': {'RequestId': '1f8acb19-5a13-4d37-bc07-b3bc9616591f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1f8acb19-5a13-4d37-bc07-b3bc9616591f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '739',\n",
       "   'date': 'Sun, 09 Jul 2023 04:11:52 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e09c05-ce26-46e3-b78b-c391fb15fb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "go = 0\n",
    "if go == 1:\n",
    "    print(\"Delete the pipeline\")\n",
    "    sagemaker_client.delete_pipeline(PipelineName=pipeline_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a21e761b-9608-4297-9dc0-c66a6cc3232f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-523914011708/aws-ray-mlops-workshop/feature-store/train/523914011708/sagemaker/us-east-1/offline-store/fs-train-synthetic-housing-data-1688849115/data'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_train_group = FeatureGroup(\n",
    "        name=\"fs-train-synthetic-housing-data\", \n",
    "        sagemaker_session=session\n",
    "    )\n",
    "\n",
    "fs_train_data_loc = fs_train_group.describe().get(\"OfflineStoreConfig\").get(\"S3StorageConfig\").get(\"ResolvedOutputS3Uri\")\n",
    "fs_train_data_loc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19568b3-8944-4b9f-8c8b-405964aa5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3://sagemaker-us-east-1-523914011708/aws-ray-mlops-workshop/feature-store/train/523914011708/sagemaker/us-east-1/offline-store/fs-train-synthetic-housing-data-1688849115/data\n",
    "\n",
    "s3://sagemaker-us-east-1-523914011708/aws-ray-mlops-workshop/feature-store/train/523914011708/sagemaker/us-east-1/offline-store/fs-train-synthetic-housing-data/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871be26b-b530-4316-b5ce-6d5bb23b3b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker', 'ray', 'modin[ray]', 'pydantic==1.10.10'])\n",
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import glob\n",
    "\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Sagemaker specific imports\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import load_run\n",
    "import modin.pandas as pd\n",
    "# Ray specific imports\n",
    "import ray\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.data import Dataset\n",
    "from ray.air.result import Result\n",
    "from ray.air.checkpoint import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ff63d-587b-4dda-ab3d-d2aceb4a8fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs_test_data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f6163-5ff3-438c-b099-a7bc75bb00b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Starting evaluation.')\n",
    "#ray.init()  \n",
    "#model_dir = '/opt/ml/processing/model'\n",
    "model_dir = './common/'\n",
    "model_path = os.path.join(model_dir, 'model.tar.gz')\n",
    "print(model_path)\n",
    "\n",
    "# Open the .tar.gz file\n",
    "with tarfile.open(model_path, 'r:gz') as tar:\n",
    "    # Extract all files\n",
    "    tar.extractall(path=model_dir)\n",
    "\n",
    "# Optional: Print the list of extracted files\n",
    "with tarfile.open(model_path, 'r:gz') as tar:\n",
    "    file_names = tar.getnames()\n",
    "    print(\"Extracted files:\")\n",
    "    for name in file_names:\n",
    "        print(name)\n",
    "\n",
    "checkpoint = ray.train.xgboost.XGBoostCheckpoint.from_directory(f'{model_dir}model.xgb/')\n",
    "predictor = ray.train.xgboost.XGBoostPredictor.from_checkpoint(checkpoint)\n",
    "print(dir(predictor))\n",
    "\n",
    "\n",
    "#test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "test_path = fs_test_data_loc\n",
    "\n",
    "all_files = glob.glob(os.path.join(fs_test_data_loc , \"/*.csv\"))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# df = pd.read_csv(test_path, header=0)\n",
    "df.head(5)\n",
    "y_test = df.iloc[:, 0].to_numpy()\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "X_test = df.to_numpy()\n",
    "predictions = predictor.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac8c32-09d1-4612-afea-1491b4a10784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b99c8f-ec80-4ca4-b7dc-18bc54b55da7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423378c-213a-4438-9146-8889c82203fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See the regression metrics\n",
    "# see: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "std = np.std(y_test - predictions)\n",
    "report_dict = {\n",
    "    'regression_metrics': {\n",
    "        'mae': {\n",
    "            'value': mae,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'mse': {\n",
    "            'value': mse,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'rmse': {\n",
    "            'value': rmse,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "        'r2': {\n",
    "            'value': r2,\n",
    "            'standard_deviation': std,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "output_dir = '/opt/ml/processing/evaluation'\n",
    "pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "evaluation_path = f'{model_dir}/evaluation.json'\n",
    "with open(evaluation_path, 'w') as f:\n",
    "    f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c329973-413b-4a9f-9d40-891a3e1af9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad054e-3eec-4e8a-84a6-486fb95bea56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python ./pipeline_scripts/evaluate/script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70722d25-a54d-4908-a742-40fd644bf633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to download the model from Sagemaker Model registry\n",
    "def download_model(model_name, download_path):\n",
    "    # Create a Boto3 SageMaker client\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "\n",
    "    # Get the details of the model package\n",
    "    response = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=model_name\n",
    "    )\n",
    "\n",
    "    # Retrieve the S3 location of the model package\n",
    "    model_package_location = response['InferenceSpecification']['Containers'][0]['ModelDataUrl']\n",
    "    print(model_package_location)\n",
    "    # Download the model package\n",
    "    s3_client = boto3.client('s3')\n",
    "    #bucket_name = 'your-bucket-name'  # Replace with your S3 bucket name\n",
    "    download_path = './common/model.tar.gz'  # Specify the local download path\n",
    "\n",
    "    s3_client.download_file(bucket, model_package_location, download_path)\n",
    "\n",
    "    print(\"Model downloaded successfully.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710f145-a271-47e8-813f-a719f5190ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_model(model_package_arn, './common/')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4bc72e2-adf8-4d2f-a9ae-265b102a262a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call show on the output probabilities to trigger execution.\n",
    "predicted_probabilities.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba828c-a98e-4fe3-a782-e8e918e8df68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af61903-2bf9-4409-b350-747415148ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89594588-22f2-4d16-b405-3215d28747a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
